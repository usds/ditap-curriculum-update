# Facilitator Guide: DITAP for Product Thinking and Acquisitions 
In this packet, you have access to the module outlines, required topics, module activities, and the **Discovery Sprint Lab**. 

## Module outline:
This provides you with a centralized location for all your module needs. You’ll find your module objectives, required topics, training artifacts, and interactive activities for participants. 
- **Objectives**: These are the high-level objectives for each module. You can add your agency’s objectives in each module as you work through the material; however, these core objectives should be achieved by participants by the end of each module. 
- **Required topics**: Each topic links out to the required curriculum. Most of the information is presented through the lens of applying a product thinking mindset to the acquisition lifecycle. 
- **Class activities**: Each module features interactive activities designed to reinforce its learning objectives.

## Learning modules:
The learning modules are the curriculum for the course. Each topic listed in the Module Outline corresponds to a specific learning module. The curriculum and case study guides appear in each learning module topic. It also includes a prompt for an optional module retrospective. Your agency determines the best way to deliver this information, whether via slide decks, in-person delivery, or virtual classroom delivery. The curriculum guides participants away from rigid procurement cycles to adaptive, iterative, and human-centered approaches, providing rapid and actionable insights into how product management principles can transform acquisition outcomes. 

## The discovery sprint labs 
**The discovery lab** is a hands-on simulation of a lightweight federal discovery sprint, introduced after Module 1. The facilitator schedules the two subsequent labs at strategic points across the remaining modules to provide participants with practical experience in applying product thinking to user research, problem framing, and acquisition planning.

## Module 1: Digital services and why product thinking matters in government

**Module overview**

This module introduces participants to the foundational concepts of digital service delivery in government and the importance of adopting a product mindset. Participants explore how product thinking differs from traditional project approaches and how it drives adaptability, user-centered value, and lasting mission impact. They also learn about the key roles and responsibilities of digital service teams and how these roles collaborate across the delivery lifecycle.

**Learning objectives**

By the end of this module, participants will be able to:
- Define what digital services are and explain how they support public missions and user-centered outcomes.
- Distinguish between a project mindset and a product mindset in the context of digital service delivery.
- Explain how adopting a product mindset improves adaptability, value delivery, and long-term impact in government services.
- Identify the key roles and responsibilities on digital service teams and describe how they collaborate across the delivery lifecycle.
- Recognize opportunities to apply product thinking and analyze how it can be used to address real-world government challenges.

**Activities and training artifacts**
- **Activity**: *Fix It Like a Product Team* – participants reflect on and discuss a real-world government service, identify missed user needs, and reimagine how a product mindset could improve the experience.
- **Optional activity**: *Module Retrospective* – participants reflect on what worked well, what could be improved, and ways to enhance the learning experience for future iterations.

**Discovery lab introduction**: The Facilitator should follow the **Lab Guide** to introduce the description and Lab 1 of the Discovery Lab Sprints. 
- **Artifacts**: Materials from Discovery Lab #1

**Facilitation tips**
- Ground the discussion in real-world relevance: Encourage participants to use examples from their agency or experience to make the concepts more tangible.
- Prompt participants to think about a government service they’ve interacted with recently, such as filing taxes, renewing a license, or applying for benefits. The service can be at the federal, state, or local level. Ask them to choose an example that feels outdated, confusing, or frustrating.
- Push beyond surface-level issues:  When participants describe a poor service experience, ask probing questions to uncover missed user needs and system-level causes.
- Reinforce product mindset language: Model language that emphasizes user outcomes, iteration, and adaptability instead of rigid delivery milestones.
- Encourage diverse perspectives: In small groups, ensure that all voices are heard and that examples reflect a variety of service types and user populations.
- Connect activity debrief to module goals: Link participant observations back to the difference between project and product mindsets and the value of continuous delivery in government.
 
## Module 2: Understanding people and problems

**Module overview**

This module equips participants with the skills to identify and frame real user problems before shaping solutions or acquisitions. Using the Discovery Sprint framework, participants analyze fictional personas, journey maps, and user research to uncover root causes, prioritize needs, and define measurable success criteria. These activities reinforce how early discovery directly impacts mission outcomes and informs more innovative procurement strategies.

**Learning objectives**

By the end of this module, participants will be able to:
- Describe the purpose and structure of a Discovery Sprint and how it supports more innovative acquisitions.
- Analyze user research to identify root problems and craft strong problem statements.
- Apply product tools such as stakeholder maps, personas, and journey maps to uncover user needs.
- Define success criteria and next steps that link user outcomes to mission goals.

**Activities and training artifacts**

Scenario: ESA Registry – _Pet.gov_
- **Activity 1**: Analyzing User Types and Their Challenges
    - Participants identify three potential personas, list three pain points per persona, and highlight the three biggest challenges, their impacts, and the consequences of inaction.
- Potential Answers to the Prompt Questions
    - Where in the journey does trust break down?
        - Steps 1 & 2: When Chloe encounters multiple unofficial and potentially predatory websites. The lack of a clear, trustworthy source immediately casts doubt.
        - Step 3: The absence of a centralized, consistent government source deepens distrust.
        - Step 4: Even a trusted authority (the therapist) cannot point to a definitive answer, which undermines confidence in the entire system.
- Facilitator Guidance: Emphasize that trust in public services depends not just on truth, but on clarity and consistency. When conflicting or unofficial sources dominate, it creates space for misinformation.
    - What’s the most emotionally frustrating moment?
        - Step 4: Being told by a campus therapist that there is no federal registry contradicts what Chloe has seen online—leading to irritation, disillusionment, and feeling unsupported.
        - Step 5: Chloe’s decision to use a questionable template shows resignation. She feels forced to rely on something unofficial and hopes it won't backfire.
- Facilitator Guidance:
Encourage students to reflect on the emotional toll of bureaucratic confusion, especially when mental health and housing are at stake. This builds empathy and supports user-centered thinking.

- **Activity 2**: Analyze the ESA Registration Journey (Part 1)
    - Participants review a fictional journey map (Chloe and “Professor Nibbles”), identify top three pain points, propose an improvement opportunity, and frame a “how might we” question.
- **Activity 3**: Define Success Criteria (Part 2)
    - Participants revisit the chosen opportunity and define 2–3 measurable, user-centered success criteria.

**Artifacts**: n/a 

**Facilitation tips**
- Ground participants in the ESA scenario: It’s fictional but realistic enough to let them safely explore discovery techniques without agency-specific constraints.
- Push for specificity: When identifying pain points, avoid vague statements like “confusing process” and probe for details about where, when, and why confusion happens.
- Model good “how might we” framing:  Keep it broad enough for creativity but anchored in the user problem, not the solution.
- Tie insights back to acquisition: Reinforce that what they surface today becomes the foundation for requirements, SOO/PWS drafting, and evaluation planning.
- Watch for premature solutioning: If groups start designing features, redirect them to dig deeper into the problem space first.
- Highlight measurability in success criteria: Remind participants that well-defined criteria can be tracked and used for oversight, not just initial planning.

## Module 3: Agile solicitations, evaluation, and award

**Module overview**

This module bridges discovery insights and acquisition execution. Participants learn how to select the right contracting approach, incorporate agile and human-centered design principles into solicitation language, estimate the cost of agile work, and design evaluation strategies that identify vendors capable of delivering iterative and collaborative solutions. Through scenario-based activities, they practice aligning acquisition structures and evaluation methods with real-world agile delivery.

**Learning objectives**

By the end of this module, participants will be able to:
- Understand the difference between a Performance Work Statement (PWS) and a Statement of Objectives (SOO), and when to use each.
- Integrate agile and human-centered design principles into acquisition language.
- Develop an Independent Government Cost Estimate (IGCE) for agile delivery work.
- Apply modern evaluation methods such as comparative analysis, live demos, and down-selects.
- Design a high-level evaluation strategy for a fictional ESA registry procurement that reflects agile best practices.
  
**Activities and training artifacts**
- **Activity 1**: PWS or SOO? Choosing the Right Agile Contracting Approach
    - Participants review the ESA registry scenario, assess readiness and clarity of requirements, and decide whether a PWS or SOO is most appropriate. They justify their choice and identify one potential risk and mitigation approach.
        - Artifacts: Delivery Sprint Report, ESA Statement of Objectives (SOO), and ESA Performance Work Statement (PWS)
- **Activity 2**: Estimating the Cost of Agile Delivery
    - Using the Agile Team Estimator tool and their earlier contracting approach decision, teams develop a draft IGCE for the ESA registry.     - They consider team composition, sprint length, number of iterations, optional tasks, and other direct costs.
        - Artifact: IGCE (Excel or worksheet) 
- **Activity 3**: Designing an Agile Evaluation Strategy
    - Teams design a phased evaluation approach for the ESA registry procurement. They define evaluation phases, criteria, proposal requirements, and collaboration/governance plans with the CO.
        - Artifact: n/a 
- **Optional activity**: Module Retrospective
    - Participants reflect on what worked, what could be improved, and how they’ll apply lessons learned in their acquisition work.

**Facilitation tips**
- Direct Participants to read the VA.gov Modernization Case Study.
- Encourage scenario-specific rationale: Push teams to justify PWS vs SOO decisions based on the conditions of their ESA scenario, not generic preferences.
- Reinforce informed trade-offs over “right answers”: Highlight that both PWS and SOO can work if matched to the proper context and readiness level.
- Tie decisions to agile team maturity and capacity: Remind participants to factor in team availability, technical readiness, and leadership appetite for iteration.
- Probe cost drivers in IGCE discussions: Ask teams what choices most influenced their estimates (e.g., sprint length, labor mix, optional sprints) and whether they reflected scenario constraints.
- Emphasize modularity in cost planning: Encourage contingency sprints and modular pricing to support flexibility.
- Highlight outcome-oriented solicitation language: Guide teams to distinguish between outcome statements (“what success looks like”) and prescriptive task lists.
- Anchor evaluation planning in agency readiness: Push for realistic, defensible evaluation strategies that the agency could execute.
- Use the VA.gov case study for inspiration: Discuss how VA structured their evaluation phases, applied comparative analysis, and designed live demos.
- Maintain team continuity across activities: Keep the same groups together for all three activities to preserve shared context and build on earlier work.

**Debrief with targeted prompts**:  
- PWS/SOO: “What tipped your team toward your decision?” “What would change your choice in a higher-risk environment?”
- IGCE: “What assumptions drove your estimate?” “How did your contracting approach influence your cost?”
- Evaluation: “What was hardest to define?” “What would you borrow from the VA process?”

## Module 4: Managing digital delivery

**Module overview**

This module focuses on post-award success for agile digital delivery. Participants examine the complementary roles of the Product Manager (PM), Product Owner (PO), and Contracting Officer’s Representative (COR) in supporting iterative delivery, maintaining oversight, and fostering collaboration. Through realistic sprint report scenarios, they practice identifying delivery risks, determining who should take action, and deciding how to respond to keep the product and contract on track. The session also addresses the difference between contract oversight metrics and agile delivery metrics, and how to use both to support mission-focused delivery.

**Learning objectives**

By the end of this module, participants will be able to:
- Describe the roles of the PM, PO, and COR in agile product delivery.
- Identify common sprint delivery issues and determine appropriate responses.
- Differentiate between contract oversight metrics and agile delivery metrics.
- Support continuous improvement and compliance through agile rituals and performance documentation.
- Foster a collaborative, mission-focused delivery environment after contract award.

**Activities and training artifacts**
- **Activity**: Sprint Report Analysis – ESA Registry Project
    - The ESA Registry development project is three months into delivery. Participants play the role of PO, COR, or PM and review a series of fictional sprint reports, each reflecting a common agile delivery challenge—missed deliverables, unplanned changes, and team strain.

**Artifacts**: n/a

**Facilitation tips** 
- Keep the analysis grounded in realistic scenarios of government delivery.
- Encourage participants to think beyond “fix the deliverable” to address root causes (e.g., transparency gaps, planning failures, team burnout).
- Draw connections between sprint observations and long-term delivery health.
- Emphasize the balance of contract oversight and agile flexibility—too much control slows delivery, too little invites unmanaged risk.
- Remind participants that delivery metrics and contract metrics must work together to tell the whole performance story.
- Ensure each group considers role-specific responsibilities when deciding who should act.
- Close with a final reflection: “What’s one thing you’ll do differently the next time you’re part of a digital delivery team?”

## Module 5: Leading with a product mindset

**Module overview**

This module focuses on the leadership behaviors, language, and cultural signals that help PMs, CORs, and other acquisition professionals champion a product mindset within their agencies. Participants learn how to recognize and model product-focused thinking in daily decisions, interactions, and communications. They explore how to influence culture without formal authority, guide teams toward outcome-focused delivery, and commit to continuous learning and reflection.

**Learning objectives**

By the end of this module, participants will be able to:
- Identify and model behaviors that reflect a product mindset.
- Demonstrate product leadership in common PM/COR scenarios.
- Influence agency culture through language, actions, and expectations.
- Apply intentional strategies for ongoing learning and reflection.

**Activities and training artifacts**
- **Activity 1**: Spot the Mindset
    - Participants review example statements and determine whether each reflects a project mindset or a product mindset. If a statement is project-focused, they rewrite it to emphasize user outcomes, evidence-based decision-making, and continuous learning.
        - Artifact: n/a
- **Optional activity**: Product Leader Journal: Participants create a short daily or weekly journal to reflect on.

**Facilitation tips**
- Encourage participants to go beyond “right or wrong” answers and explain why a statement reflects a project or product mindset.
- Use real-world examples from participants’ agencies to connect abstract mindset shifts to concrete behaviors.
- Reinforce that language shapes culture—model outcome-focused language during facilitation.
- Push for evidence-based thinking by asking, “What user needs or data supports this decision?”
- In the Product Leader Journal, emphasize honest self-reflection and tracking progress over time.
- Close with commitment sharing: ask participants to identify one behavior they will model in the next month that reflects a product mindset.
