<img width="1224" height="400" alt="Leading through risk case study activity" src="https://github.com/user-attachments/assets/5b3b1141-8f27-4855-b98b-aa1c2bdd99af" />

# Case Study Exercise: Leading Through Risk

**Scenario setup**: Roman has identified several risks in the Project RAINBO approach. Your executive leadership team must assess these risks and develop strategies that strike a balance between innovation and responsible risk management.

<img width="1224" height="400" alt="exercise instructions" src="https://github.com/user-attachments/assets/5e78b6d4-676f-4048-83e9-018d80f87404" />

## Exercise instructions:
**Part A: Risk assessment matrix** (20 minutes)

Teams analyze Roman's specific risk statements from the case:

**Identified risks**:
- "We can't just play around with technology we don't understand."
- "Anything below TRL 7 is too risky to consider."
- "Modular contracting would make things less efficient and riskier."
- "We'd end up with a protest if we require interoperability."

**Risk categorization**: Plot each risk on a 2x2 matrix:
- X-axis: Probability (Low to High)
- Y-axis: Impact (Low to High)

**Risk type analysis**: For each risk, determine:
- Is this legal sufficiency or excessive risk aversion?
- What's the actual regulatory requirement vs. organizational habit?
- What's the cost of inaction vs. action?

**Part B: User story development** (25 minutes)

Each team member writes a user story for one risk they want to address:

Template: "_As a [role], I want to [action] so that [benefit]._"
- Example: "As an executive leader, I want to establish TRL flexibility guidelines so that our teams can pursue emerging technologies while maintaining appropriate oversight."

**Requirements for each user story**:
- Clear stakeholder identification
- Specific, measurable outcome
- Alignment with mission objectives
- Consideration of regulatory requirements

**Part C: MVP solution development** (15 minutes)

Teams select one user story as their MVP (Minimum Viable Product) and develop:
- Immediate actions (next 30 days)
- Short-term implementation (next 90 days)
- Long-term systemic change (next year)

Each solution should address:
- How executive influence enables change
- What policy or process modifications are needed
- How to measure success
 
## Lean Procurement Canvas Exercise
Instructions: Teams complete a Lean Procurement Canvas for Project RAINBO

### Canvas sections:
**Problem Segments**:
- What specific problems does healthcare data management solve?
- Who experiences these problems most acutely?
- What are the current workarounds or solutions?

**Value Propositions**:
- What unique value does improved data management provide?
- How does AI enhancement change the value equation?
- What outcomes matter most to users?

**Solution Approach**:
- What's the minimum viable solution?
- How do we validate assumptions quickly?
- What can we learn before committing to complete development?

**Key Metrics**:
- How do we measure user success?
- What technical performance indicators matter?
- How do we track progress toward outcomes?

**Channels**:
- How do users access the system?
- What integration points are required?
- How do we support adoption?

**Cost Structure**:
- What are the main development costs?
- How do we structure payments to align with value?
- What's the total cost of ownership?

**Revenue Streams**:
- How does this system create value for the organization?
- What's the return on investment?
- How do we sustain funding?

## Applying Strategic Acquisition Leadership: Project RAINBO Integration
The exercises that follow integrate your learning about strategic acquisition leadership, risk management, and culture change. You'll practice:
- Using acquisition strategy tools to structure complex procurement decisions.
- Applying risk management frameworks to balance innovation with accountability.
- Translating user needs into acquisition language that enables vendor innovation.
- Promoting culture change through executive leadership and decision-making.
- Managing stakeholder expectations while enabling organizational transformation.

As you work through these exercises, focus on your role as an executive leader:
- What strategic decisions can only you make?
- How will you balance competing risks and priorities?
- What organizational changes need your authority and influence?
- How will you communicate progress and learning to stakeholders?

## Your Strategic Acquisition Action Plan

Based on your learning in this module, create your specific plan for leading strategic acquisition transformation:
 
1. Next 30 Days: Foundation and Assessment
- [ ] Review your current acquisition portfolio using the three-horizon framework.
- [ ] Identify your biggest acquisition challenge and its root causes.
- [ ] Map stakeholder interests and resistance to modern procurement approaches.
- [ ] Assess your team's readiness for strategic acquisition approaches.
- [ ] Select one acquisition to pilot new approaches.
- [ ] Engage legal counsel to understand actual vs. perceived requirements.
- [ ] Begin building coalition support for acquisition innovation.
- [ ] Establish success metrics that focus on user outcomes.

2. Month 2 Focus: Capability Building and Pilot Launch
- [ ] Launch pilot acquisition using modern approaches.
- [ ] Implement user feedback collection and integration processes.
- [ ] Begin changing performance metrics and recognition systems.
- [ ] Document lessons learned and share with stakeholders.
- [ ] Address resistance and barriers as they emerge.

3. Next 90 Days: Scaling and Institutionalization
- [ ] Expand successful approaches to additional acquisitions.
- [ ] Modify policies and processes based on pilot learning.
- [ ] Build a vendor ecosystem capable of supporting modern approaches.
- [ ] Create training and development programs for acquisition innovation.
- [ ] Establish ongoing measurement and improvement processes.

## Strategic Acquisition Leadership Success Indicators
You'll know you're succeeding when:
- Teams propose user-centered acquisition strategies without prompting.
- Legal counsel actively helps find compliant ways to enable innovation.
- Vendors compete on user outcomes rather than just technical compliance.
- Stakeholders ask for user feedback data in acquisition reviews.
- Your acquisition cycle times decrease while user satisfaction increases.

## Common Strategic Acquisition Pitfalls to Avoid
- Delegating strategic decisions:
    - Only executives can set risk tolerance and strategic direction.
- Under-investing in change management:
    - Technical solutions without cultural change will fail.
- Moving too fast without foundation:
    - Build capabilities before attempting complex acquisition.s
- Ignoring stakeholder management:
    - Resistance can even undermine the best technical approaches.
- Measuring inputs instead of outcomes:
    - Focus on user value, not process compliance

**_Remember: Strategic acquisition leadership is about creating conditions that enable the best solutions to emerge and be successfully implemented. Focus on building capabilities, managing risks intelligently, and changing organizational culture to support mission success_**.

<img width="1224" height="400" alt="Exercises Answer key" src="https://github.com/user-attachments/assets/fe38b238-77e3-47e1-9899-07a0e40b6a3f" />

## Exercise Instructions Answer Key
_Part A: Risk assessment matrix_ (20 minutes)

**Roman's risk statement analysis - Detailed framework:**

Risk statement 1: "_We can't just play around with technology we don't understand_."

Risk type analysis:
- Classification: Excessive risk aversion disguised as prudence.
- Actual legal requirement: Understanding technology sufficiently for responsible oversight and contract management.
- Organizational habit vs. requirement: Roman conflates "understanding" with "complete mastery", government needs sufficient understanding for oversight, not technical expertise.
- Evidence: No FAR or regulatory requirement mandates a complete technical understanding before adoption.

Risk matrix positioning:
- Probability: Medium (30-50%) - Technology adoption always involves some uncertainty.
- Impact: High - If truly mismanaged, could lead to project failure, but this risk is manageable through proper oversight.
- Mitigation strategy: Structured experimentation with clear learning objectives, technical advisory support, and pilot programs.

Cost analysis:
- Cost of inaction: Missing breakthrough technologies, competitive disadvantage, solving yesterday's problems with yesterday's solutions.
- Cost of action: Structured learning investment, technical advisory costs, pilot program resources.
- Recommendation: Action costs significantly lower than inaction costs.

Risk statement 2: "_Anything below TRL 7 is too risky to consider_."

Risk type analysis:
- Classification: Excessive risk aversion with no legal basis
- Actual legal requirement: No FAR or statutory requirement mandates TRL 7 for all government systems.
- Organizational habit vs. requirement: TRL requirements should be risk-based and mission-appropriate, not universally applied.
- Evidence: DoD and other agencies successfully use lower TRL technologies when mission-appropriate.

Risk matrix positioning:
- Probability: High (70-90%) - Rigid TRL requirements will limit innovation.
- Impact: High - Missing critical technology opportunities, reduced competitive advantage.
- Mitigation strategy: Risk-based TRL requirements tied to specific use cases and mission criticality.

Cost analysis:
- Cost of inaction: Innovation stagnation, competitive disadvantage, inability to address emerging threats.
- Cost of action: Enhanced technical oversight, structured risk management, learning investments.
- Recommendation: Risk-based approach with appropriate oversight.

Risk statement 3: "_Modular contracting would make things less efficient and riskier_."

Risk type analysis:
- Classification: Excessive risk aversion based on unfamiliarity rather than evidence.
- Actual legal requirement: FAR 39.103 encourages modular contracting for IT systems.
- Organizational habit vs. requirement: Comfort with traditional approaches doesn't make alternatives illegal or inappropriate.
- Evidence: Multiple successful modular contracting examples across government.

Risk matrix positioning:
- Probability: Low (10-30%) - Well-implemented modular contracting typically reduces risk.
- Impact: High - If poorly implemented, could create integration challenges, but this is a manageable risk.
- Mitigation strategy: Pilot modular approach with appropriate integration planning and oversight.

Cost analysis:
- Cost of inaction: Vendor lock-in, reduced flexibility, higher long-term costs, delayed delivery.
- Cost of action: Enhanced product management capability, integration planning, vendor coordination.
- Recommendation: Pilot approach with structured learning and capability building.

Risk statement 4: "_We'd end up with a protest if we require interoperability_."

Risk type analysis:
- Classification: Legal sufficiency concerns with some merit, but manageable.
- Actual legal requirement: Competition requirements must be fair and clearly defined.
- Organizational habit vs. requirement: Protest avoidance vs. mission-effective competition.
- Evidence: Interoperability requirements are standard and legally defensible when properly structured.

Risk matrix positioning:
- Probability: Medium (30-50%) - Protest risk exists but is manageable with proper planning.
- Impact: Medium - Protests cause delays but don't necessarily prevent good outcomes.
- Mitigation strategy: Industry engagement, clear technical standards, transparent competition process.

Cost analysis:
- Cost of inaction: Vendor lock-in, reduced system flexibility, higher long-term costs.
- Cost of action: Legal review, industry engagement, technical standards development.
- Recommendation: Structured approach with legal support and industry engagement.
 
### Facilitator guidance for risk assessment:

Common participant errors:
- Risk conflation: Participants may treat all risks as equally serious.
- Legal confusion: Teams may assume organizational preferences are legal requirements.
- Probability overestimation: Fear-based assessment rather than evidence-based analysis.
- Impact underestimation: Not considering the long-term consequences of inaction.

Facilitation questions:
- "What's the actual legal requirement here vs. organizational preference?"
- "What evidence supports this risk assessment?"
- "What's the cost of not taking this risk?"
- "How have other organizations handled similar risks?"
- "What would need to be true for this risk to materialize?"

Quality indicators:
- Good analysis: Evidence-based risk assessment distinguishes legal requirements from preferences, considers both action and inaction costs.
- Poor analysis: Fear-based assessment, conflates preferences with requirements, ignores inaction costs.

**Part B: User story development** 

Sample user stories for each risk area:
- TRL flexibility user story:
    - User story: "As an executive leader, I want to establish risk-based technology readiness guidelines so that our teams can pursue emerging technologies while maintaining appropriate oversight for mission-critical applications."
- Acceptance criteria:
    - Guidelines differentiate between mission-critical and experimental applications.
    - The risk assessment framework considers both technology maturity and mission impact.
    - Approval process scales with risk level and potential impact.
    - Clear escalation paths for high-risk/high-reward opportunities.

- Modular contracting user story:
    - User story: "As a program manager, I want to pilot modular contracting approaches so that we can reduce vendor lock-in and accelerate delivery while building organizational competence."
- Acceptance criteria:
    - Pilot project selected with appropriate scope and complexity.
    - Integration requirements are clearly defined and testable.
    - Success metrics include both delivery speed and integration effectiveness.
    - Lessons learned captured for future applications.

- Innovation space user story:
    - User story: "As a contracting officer, I want clear policy guidance on experimental authorities so that I can support innovation while maintaining legal sufficiency."
- Acceptance criteria:
    - Policy guidance covers available authorities and their appropriate use.
    - Legal review process tailored to innovation requirements.
    - Training provided on new authorities and their application.
    - Support is available for complex or novel situations.

- Stakeholder alignment user story:
    - User story: "As a user representative, I want regular demonstration of working software so that I can provide feedback and ensure the solution meets actual needs."
- Acceptance criteria:
    - Demonstration schedule established and maintained.
    - The feedback mechanism captures user input effectively.
    - Changes based on feedback are tracked and implemented.
    - User satisfaction is measured and reported regularly.

### Facilitator guidance for user story development:
Individual writing process:
- Time management: Allow 5-7 minutes per user story.
    - Focus areas: Each team member should tackle different risks.
    - Quality check: Stories should be specific, measurable, and mission-aligned.
    - Sharing process: Brief presentations with peer feedback.

Common challenges:
- Solution focus: Participants may write about solutions rather than outcomes.
- Generic users: Teams may create vague user personas.
- Unrealistic scope: Stories may be too large or complex for the MVP approach.
- Regulatory naivety: May ignore legal and compliance requirements.

Facilitation interventions:
- Outcome focus: "What specific benefit does this user receive?"
- User specificity: "Who exactly would use this capability?"
- Scope reality: "What's the smallest version that would provide value?"
- Regulatory check: "What legal requirements apply here?"

 
**Part C: MVP solution development**

Selection criteria:
- User impact: How many users benefit and how significantly?
- Implementation feasibility: Can this be accomplished with available resources?
- Learning potential: How much will this teach us about the problem space?
- Risk mitigation: How does this address the most critical risks?
- Scalability: Can this solution scale to meet larger needs?

**Sample MVP solution: Risk-based TRL guidelines**

User story: "_As an executive leader, I want to establish risk-based technology readiness guidelines so that our teams can pursue emerging technologies while maintaining appropriate oversight for mission-critical applications_."

Immediate actions (Next 30 days):
- Week 1: Convene working group with technical experts, legal counsel, and program managers.
- Week 2: Review current TRL policy and identify actual vs. perceived requirements.
- Week 3: Benchmark other agencies' approaches to emerging technology adoption.
- Week 4: Draft an initial framework document for internal review.

Short-term implementation (Next 90 days):
- Month 2: Refine framework based on stakeholder feedback and legal review.
- Month 3: Pilot framework with one low-risk, high-learning project.
- Month 3: Develop training materials and communication strategy.
- Month 3: Establish measurement criteria and feedback mechanisms.

Long-term systemic change (Next year):
- Months 4-6: Integrate guidelines into agency acquisition policy and procedures.
- Months 7-9: Establish ongoing technology assessment and advisory capability.
- Months 10-12: Create innovation-friendly procurement processes and vendor engagement.
- Ongoing: Regular review and adaptation based on experience and the changing technology landscape.

**Executive influence integration**:

Resource allocation:
- Budget: Fund working group activities, training development, and pilot project support.
- Personnel: Assign dedicated staff to framework development and implementation.
- Time: Protect time for stakeholder engagement and policy development.
- Authority: Provide decision-making authority for framework adoption.

Policy and process modification:
- Policy updates: Modify existing policies to incorporate a risk-based approach.
- Process changes: Adapt approval processes to accommodate the new framework.
- Training programs: Develop and deliver training on new approaches.
- Communication strategy: Articulate vision and benefits to stakeholders.

Cultural change support:
- Leadership modeling: Demonstrate comfort with appropriate risk-taking.
- Success recognition: Celebrate successful applications of the new framework.
- Failure tolerance: Treat intelligent failures as learning opportunities.
- Continuous improvement: Adapt the approach based on experience and feedback.

**Success measurement framework**:

Leading indicators:
- Policy adoption: Number of projects using the new framework.
- Training completion: Percentage of relevant staff trained.
- Stakeholder engagement: Participation in working groups and feedback sessions.
- Process efficiency: Time reduction in technology approval processes.

Lagging indicators:
- Innovation outcomes: Number of emerging technologies successfully adopted.
- Mission impact: Improvements in mission effectiveness and competitive advantage.
- Risk management: Balance of innovation success with appropriate risk management.
- Organizational learning: Capability development and knowledge retention.

### Facilitator guidance for MVP development:
Team selection process:
- Voting method: Teams vote on user stories based on impact and feasibility.
- Consensus building: Brief discussion to reach agreement on selection.
- Backup planning: Identify a secondary choice in case the primary proves too complex.
- Reality check: Ensure the selected story is achievable within resource constraints.

Development process:
- Structured planning: Use the provided template for immediate, short-term, and long-term actions.
- Resource consideration: Consider available personnel, budget, and time constraints.
- Stakeholder mapping: Identify who needs to be involved in each phase.
- Risk assessment: Consider implementation risks and mitigation strategies.

Common MVP problems:
- Scope creep: Solutions that grow beyond the minimum viable scope.
- Resource unrealism: Plans that exceed available resources.
- Stakeholder neglect: Plans that ignore key stakeholder needs.
- Measurement gaps: Solutions without clear success criteria.

Facilitation interventions:
- Scope management: "What's the smallest version that would provide value?"
- Resource reality: "What resources do you have available?"
- Stakeholder check: "Who needs to be involved for this to succeed?"
- Success criteria: "How will you know this is working?"

Quality indicators:
- Good MVP: Realistic scope, adequate resources, stakeholder engagement, clear success criteria.
- Poor MVP: Unrealistic scope, insufficient resources, stakeholder neglect, vague success criteria.
 
## Lean Procurement Canvas Exercise

**Canvas section development**:

Problem segments - Expected answers:
- Healthcare data integration: Fragmented systems prevent comprehensive patient care.
- Research limitations: Researchers cannot access integrated datasets for medical breakthroughs.
- Compliance challenges: Administrators struggle with data consistency and regulatory requirements.
- Decision delays: Clinicians waste time accessing data instead of treating patients.

Value propositions - Expected answers:
- Unified data access: Single point of access for comprehensive patient information.
- AI-powered insights: Machine learning capabilities that accelerate diagnosis and treatment.
- Regulatory compliance: Automated compliance monitoring and reporting.
- Research acceleration: Integrated datasets enable faster medical research and discovery.

Solution approach - Expected answers:
- Minimum viable solution: Single-hospital data integration with basic AI capabilities.
- Validation strategy: User interviews, prototype testing, pilot deployment with feedback loops.
- Learning priorities: User workflow integration, data quality requirements, AI effectiveness.
- Scaling plan: Expand to multiple hospitals, add advanced AI features, and integrate with external systems.

Key metrics - Expected answers:
- User success: Time to access patient data, clinical decision-making speed, and user satisfaction.
- Technical performance: System uptime, data accuracy, integration success rates.
- Business impact: Cost reduction, efficiency improvements, patient outcome improvements.
- Innovation indicators: New insights discovered, research acceleration, breakthrough treatments.

Channels - Expected answers:
- Primary access: Web-based clinical dashboard optimized for healthcare workflows.
- Mobile access: Tablet and smartphone applications for point-of-care use.
- Integration points: APIs connecting to existing hospital information systems.
- Support channels: Training programs, help desk, technical documentation.

Cost structure - Expected answers:
- Development costs: Software development, AI model training, system integration.
- Infrastructure costs: Cloud hosting, data storage, security systems.
- Operational costs: Ongoing maintenance, support, training, updates.
- Integration costs: API development, data migration, system testing.

Revenue streams - Expected answers:
- Organizational value: Improved patient outcomes, operational efficiency, competitive advantage.
- Cost savings: Reduced administrative burden, faster decision-making, reduced errors.
- Revenue generation: Better patient care leading to improved reputation and volume.
- Innovation value: Research breakthroughs, new treatment capabilities, knowledge advancement.

### Facilitator guidance for the canvas exercise:
Canvas completion process:
- Time management: Allow 4-5 minutes per section, enforce time limits.
- Collaboration: Encourage all team members to contribute to each section.
- Specificity: Push for concrete examples rather than abstract concepts.
- Integration: Ensure sections connect logically and support each other.

Common canvas problems:
- Generic solutions: Vague descriptions that could apply to any system.
- Technology focus: Emphasis on features rather than user value.
- Unrealistic metrics: Unmeasurable or irrelevant success indicators.
- Cost ignorance: Underestimating development and operational costs.

Facilitation questions:
- Problem focus: "Who specifically experiences this problem and how?"
- Value clarity: "What specific value does this provide to users?"
- Solution realism: "What's the simplest version that would work?"
- Metric relevance: "How does this metric connect to mission success?"

Quality indicators:
- Good canvas: Specific problem focus, clear value proposition, realistic solution approach, measurable metrics.
- Poor canvas: Generic problems, vague value, unrealistic solutions, unmeasurable metrics.

## Discussion Questions Answer Key 
_Question 1: How do you translate user needs into language that drives acquisition?_
- Complete answer: Translating user needs into acquisition language requires a systematic approach that maintains focus on user outcomes while providing vendors with precise, actionable requirements that can be evaluated and delivered within government procurement frameworks.

Key learning points:
- Start with user research and validation:
    - Before writing any requirements, conduct direct user research to understand actual needs, pain points, and success criteria. This prevents the common problem of translating assumed needs rather than validated user requirements. Use ethnographic research, user interviews, and task analysis to understand how users work, not how processes assume they work.
- Focus on outcomes, not outputs:
    - Traditional acquisition language often specifies what to build (outputs) rather than what to achieve (outcomes). User-centered acquisition language describes the problems to be solved and the success criteria to be met, giving vendors the flexibility to propose optimal solutions. For example, instead of "build a dashboard with 15 specific data fields," write "enable clinicians to access patient history within 30 seconds to support treatment decisions."
- Use Performance Work Statements (PWS):
    - Structure requirements around desired outcomes and performance standards rather than detailed technical specifications. PWS documents should focus on what the system must accomplish for users, how success will be measured, and what constraints exist. This approach enables vendor innovation while ensuring accountability for results.
- Include user acceptance criteria:
    - Clearly define how success will be measured from the user perspective, including usability standards, performance benchmarks, and satisfaction metrics. Acceptance criteria should be specific, measurable, and tied to actual user workflows. For example, "95% of users can complete the primary task without training or support."
- Maintain traceability:
    - Ensure every requirement can be traced back to a specific user need or mission objective. This prevents scope creep and ensures relevance throughout the project lifecycle. Create a requirements traceability matrix that connects user research findings to functional requirements to acceptance criteria.
- Use plain language:
    - Write requirements in language that users can understand and validate. Avoid technical jargon and focus on user goals and outcomes. This enables user participation in requirement validation, ensuring that vendors understand user needs.

**Facilitator notes**:
- Emphasize that this is a skill that requires practice and iteration.
- Encourage participants to share examples from their own experience.
- Highlight the importance of user involvement throughout the process.
- Address common concerns about losing technical precision.

_Question 2: What's the difference between legal sufficiency and excessive risk aversion?_
- Complete answer: Legal sufficiency focuses on meeting actual regulatory requirements and protecting against genuine legal risks. In contrast, excessive risk aversion goes beyond legal requirements to avoid any possibility of criticism or challenge, often at the expense of mission effectiveness and innovation.

Key learning points:
- Legal sufficiency characteristics:
    - Legal sufficiency entails understanding and complying with actual legal requirements, consulting with legal counsel as necessary, and accurately documenting decisions. It focuses on enabling mission success while protecting against real legal risks. This includes following the Federal Acquisition Regulation (FAR), agency-specific regulations, and applicable statutes, but interpreting them in ways that enable rather than obstruct mission accomplishment.
- Excessive risk aversion indicators:
    - Excessive risk aversion often manifests as inflexible adherence to past practices, unwillingness to use available authorities, treating guidance as requirements, and prioritizing process perfection over mission outcomes. Common indicators include: requiring approvals not mandated by regulation, applying conservative interpretations without legal basis, avoiding new approaches regardless of potential benefits, and creating process requirements that exceed legal mandates.
- The executive's role in distinguishing:
    - Executives must challenge their teams to differentiate between real legal requirements and organizational habits. This approach requires asking tough questions about the source of requirements, the consequences of different methods, and the impact of conservative interpretations on the mission. Leaders should work with legal counsel to understand what is required versus what is traditionally done.
- Cultural impact:
    - Excessive risk aversion fosters a culture where innovation is discouraged, and teams tend to default to the most conservative approach, regardless of mission needs. This approach ultimately increases the risk of mission failure while creating the illusion of safety. It also drives away talented people who want to work on meaningful challenges with modern approaches.
- Practical application:
    - Teams should regularly review their risk assumptions, consult with legal counsel about actual requirements, and benchmark against other successful organizations to calibrate their risk tolerance appropriately. The goal is intelligent risk management that enables mission success, not risk avoidance that prevents mission accomplishment.

**Facilitator notes**:
- Encourage participants to share examples of both legal sufficiency and excessive risk aversion.
- Emphasize the importance of consulting with legal counsel for actual requirements.
- Highlight the mission impact of excessive risk aversion.
- Address concerns about career safety and organizational protection.

_Question 3: How do modern contract types support digital services?_
- Complete answer: Modern contract types enable the iterative, user-feedback-driven development that digital services require, shifting away from traditional fixed-scope approaches toward flexible arrangements that support continuous delivery and improvement.

Key learning points:
- Agile-compatible contract types:
    - Time and Materials (T&M) contracts offer flexibility for iterative development, allowing the scope to evolve based on user feedback. Labor Hour contracts support user research and discovery phases where specific deliverables cannot be predetermined. Indefinite Delivery/Indefinite Quantity (IDIQ) contracts enable ongoing iteration and continuous delivery of capabilities.
- Performance-based contracting:
    - Structure payments around working software demonstrations and user acceptance rather than traditional milestones. This approach aligns vendor incentives with user outcomes, encouraging continuous delivery. Payment should be tied to value delivered to users, not just effort expended or features completed.
- Modular contract approaches:
    - Utilize multiple smaller contracts rather than a single large, monolithic contract. This approach reduces vendor lock-in, enables competition for different components, and allows for course corrections without requiring renegotiation of entire agreements. Modular approaches also enable parallel development and faster overall delivery.
- Key contract features:
    - Include provisions for user feedback integration, iterative delivery requirements, and collaborative working arrangements. Contracts should support the government's need for continuous oversight and course correction while enabling vendor innovation and efficiency.

**Facilitator notes**:
- Emphasize the importance of aligning contract structure with desired outcomes.
- Encourage discussion of participants' experiences with different contract types.
- Highlight the role of legal counsel in structuring innovative contracts.
- Address concerns about compliance and risk management.

_Question 4: How do you structure acquisition strategies for agile development?_
- Complete answer: Agile acquisition strategies must accommodate uncertainty, iteration, and continuous user feedback while maintaining appropriate oversight and accountability for public funds.

Key learning points:
- Embrace uncertainty:
    - Traditional acquisition assumes complete requirements definition upfront. Agile acquisition acknowledges that requirements will evolve based on user feedback and learning, and structures contracts to accommodate this reality. This approach requires comfort with ambiguity and trust in the iterative process to produce better outcomes.
- Iterative delivery framework:
    - Structure acquisitions around regular delivery of working software rather than traditional milestone-based approaches. This approach enables continuous value delivery and reduces the risk of building the wrong solution. Deliveries should be frequent (typically every 2-4 weeks) and demonstrate working functionality.
- User-centered oversight:
    - Replace traditional project management oversight with product management approaches that focus on user outcomes and value delivery rather than process compliance. This approach requires government product managers who can make day-to-day decisions about priorities and requirements.
- Vendor collaboration model:
    - Structure vendor relationships as partnerships rather than traditional buyer-supplier arrangements. This approach includes transparent communication, shared risk, and collaborative problem-solving. Vendors should be involved in planning and problem-solving activities, not just execution.
- Flexible funding approaches:
    - Use funding mechanisms that support iterative development, including incremental funding, modular budgeting, and performance-based payments tied to user value delivery. Avoid funding approaches that require complete scope definition upfront.

**Facilitator notes**:
- Emphasize the cultural change required for agile acquisition.
- Encourage discussion of organizational barriers and enablers.
- Highlight the importance of government product management capabilities.
- Address concerns about oversight and accountability.

### Additional facilitator guidance:
Module integration:
- Connect risk management concepts to CVF from Module 1
- Prepare for vendor evaluation concepts in Module 4
- Emphasize the role of user needs from Module 2
- Set up change management concepts for Module 5

Common participant concerns:
- Fear of career impact from risk-taking
- Uncertainty about legal requirements
- Lack of experience with modern approaches
- Organizational resistance to change

Success indicators:
- Participants can distinguish legal requirements from organizational habits.
- Teams develop realistic implementation plans.
- Discussion focuses on mission outcomes rather than process compliance.
- Participants demonstrate understanding of user-centered approaches.
