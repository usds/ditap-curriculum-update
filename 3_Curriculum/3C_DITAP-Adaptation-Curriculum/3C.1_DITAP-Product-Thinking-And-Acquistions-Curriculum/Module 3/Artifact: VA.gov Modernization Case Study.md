# VA.gov Modernization Case Study

This case study highlights how the Department of Veterans Affairs (VA) modernized its approach to evaluating digital service proposals using a simplified and agile-friendly method. It focuses on the instructions given to offerors and the evaluation techniques applied.

*This is a condensed version of the **Case Study: VA.gov Modernization**. Read the entire case study on the [TechFAR Hub](https://techfarhub.usds.gov/resources/case-studies/va-dot-gov-modernization/).* 

## Contract Information

* **Title:** VA.gov Modernization \# Applicable FAR Part(s): FAR Part 13.1, Simplified Acquisition Procedures  
* **Total Task Order Value (Firm Fixed Price):** $5,998,319.98 (inclusive of options)  
* **Period of Performance:** 6-month Base period followed by two 6-month option periods.  
* **Scope:** The Contractor will implement a Content Management System and provide additional support for the VA Digital Modernization Strategy through improvements to VA.gov. Key 

## The Problem

The Web Brand Consolidation Working Group was created to take action on the modernization of VA's primary Veteran-facing web properties: va.gov, vets.gov, myhealth.va.gov, ebenefits.va.gov, and explore.va.gov. The group identified four key problems with the current Veteran experience across these web properties:

* Veterans cannot find the tools and services they need online
* Users are confused by the disjointed navigation between sites
* VA web sites are designed for the Administrations, not users
* Cross-administration governance of VA.gov is complicated

To address these problems, the Working Group decided to design and build a new Veteran-first experience for VA.gov. 

From a contracting perspective, the challenge was to find a capable vendor who had the necessary experience with an open-source CMS and significant expertise in agile development and user centered design. Traditionally, this would have taken the form of a request for written proposals which document each Offeror’s overall technical approach and their expertise with an open-source CMS technology. However, in the past this has proven an imperfect solution as a written proposal only allows evaluators to read a proposed approach which does not always effectively validate the ability of a vendor to actually perform in accordance with that written approach.

## The Solution

To ensure we had the largest possible pool of talent from which to choose, based on market research, it was determined an open market acquisition strategy using Simplified Acquisition Procedures (SAP) in accordance with FAR Part 13.1 was best. Since SAP provides significant flexibility in the evaluation and award of commercial contracts, we tailored an innovative multi-step approach that used:

* Case Studies  
* A short Written Technical Solution  
* An in-person technical demonstration  
* A final PWS negotiation round with the apparent winner to transition from a Statement of Objective (SOO) (used in the solicitation) to a Performance Work Statement based on the Offeror’s technical approach. 

This approach allowed us to not only ensure the proper technical expertise and approach would be implemented upon award, but as we were able to actually see the proposed vendor team perform, provided us the confidence they would be capable of meeting our innovative technical needs after the award of a contract. Additionally, SAP provides many streamlined procedures, like comparative analysis, which has the potential to significantly improve VA’s ability to find the right vendor to meet its technical needs. 

## Comparative Analysis

The problem is, especially for agile services, it can be very difficult to predetermine technical discriminators that are flexible enough to fairly evaluate often very different agile processes. To ensure vendors are not forced to augment their agile approaches to meet often arbitrary solicitation provisions, which can drastically affect their ability to perform, it was determined that the comparative analysis techniques allowed under FAR Part 13 were the best path forward. 

Comparative analysis allows us to compare proposals to each other, rather than against a pre-determined set of discriminators, so vendors were not forced to fit their proposals into a “box” created by our discriminators. Comparative Analysis was used at each Step of the evaluation process and was instrumental in the success of this acquisition. The acquisition utilized a combined synopsis/solicitation in accordance with FAR 12.603 and it was publicized on the Federal Business Opportunities (FBO) web portal.

## Step 1 – Case Studies

The solicitation requested each Offeror’s proposed open-source CMS and a set of Case Studies highlighting each Offeror’s relevant past-experience with respect to that CMS including the following information:

A. Client organization name  
B. Period of performance  
C. Quoter’s role  
D. Goals and outcomes  
E. Technology solution  
F. Delivery Methodology

This allowed us to quickly sort through those that provided detailed and relevant case studies showing expertise supporting the proposed open-source CMS, and those that provided compliant CMSs, but vague or non-relevant Case Studies that indicated they didn’t have the specific skill sets needed to support this project. 

As expected, we were able to quickly cut down to a small subset of vendors with the necessary expertise and move onto the remaining steps of the process only with those vendors. Specifically, of the seven initial respondents, three were determined to be suitable and capable of meeting VA’s needs and were moved into the next round of the process, Due Diligence.

## Due Diligence (Non-Evaluated)

The FAR encourages open communication with offerors, especially before proposals are submitted. While traditional processes rely on formal, written Q\&As to ensure fairness, this can discourage vendors from asking important questions. Fortunately, the FAR, particularly under Parts 8 and 13, is flexible and allows for one-on-one discussions or “Due Diligence” with technically acceptable offerors, as long as they are fair and reasonable. These informal exchanges are often critical to successful acquisitions.

To encourage open dialogue, VA held 30-minute one-on-one phone calls with each vendor. These “Due Diligence” sessions helped both sides clarify needs and approaches without revealing strategies to competitors. The calls were non-evaluated, structured for fairness, and followed by requests for written technical and price proposals, as well as technical demonstrations.

## Written Technical Solution

Each Offeror was asked to send a 10-page Technical Solution related to how they would implement the CMS within the new VA.gov website. Specifically, each Offeror was asked to describe the following:

1. Overall methodology and approach to plan, implement, and configure the proposed CMS for VA.gov.
2. Knowledge and approach to Agile software development.
3. Knowledge and approach to User Centered design.
4. Knowledge and approach to Development Operations (DevOps).
5. Knowledge and approach to Content Writing.
6. What the Quoter would need from the Government to ensure success and any barriers that would reduce or delay success.
7. How success and end user satisfaction will be determined and the strategy for capturing both product metrics and process metrics.
8. The proposed Labor Mix and Level of Effort by Iteration supporting the proposed firm-fixed-price. This description shall indicate whether the Labor Category is being proposed for the Prime or a subcontractor including which proposed subcontractor. Please include Labor Category descriptions for each Labor Category proposed including the experience, skill sets, and education for each Category.

The Written Technical Solutions were similar to the typical Written Proposals, however, since **we had a Technical Demonstration we could use to measure each Offeror’s agile process and capability and suitability to do the work**, we were able to keep the Written portion significantly shorter which helped speed up the process but also allowed our technical evaluators to see at a high level how each vendor would tackle the specific technical needs of the project. In addition to the Written Technical Solution, each Offeror provided a price proposal volume based on its Technical Approach.

## Price Proposal

It is difficult in advance of seeing the exact agile methodology of each vendor, where things like the length of iterations and make-up of the proposed team may differ greatly between contractors, it can be difficult to figure out how to set up a Schedule of Deliverables (Section B) for the solicitation that does not box a vendor in and force them to augment their normal technical approach. To allow vendors the flexibility to provide pricing in line with their agile approach, vendors were provided a template which they could tailor. Specifically, the solicitation requested the following:

Vendors shall fill in the provided Section B document their proposed Contract Line Items (CLINs) and provide fill-ins as included in each CLIN, and a unit price and extended price for each CLIN. Vendors are free to add additional CLINs to support their proposed price. 

Additionally, a price proposal shall be submitted in Microsoft Excel spreadsheet format. The first tab shall be a summary to include a top-level rollup of the total dollars and percentages by labor, materials, travel, Other Direct Costs, and total Task Order price. Labor shall further be broken out by labor categories, labor rates, and hours. A separate tab shall be used for the Prime and each Subcontractor. Additionally, any material or travel handling rates proposed for the Material or Travel line items shall be noted as well.

VA’s pricing approach gave vendors flexibility while requiring detailed backup (e.g., labor hours, categories, and rates) to support a fair and thorough price evaluation. Since agile work is hard to scope precisely, VA shared its estimated budget upfront. This encouraged vendors to focus on maximizing value rather than underbidding—helping enable both comparative analysis and best-value trade-offs.

## Technical Capabilities Demonstration (TCD)

In the final evaluation step, vendors were given four hours to build a working prototype in their proposed CMS, based on a fictional government scenario. Two VA staff acted as the Business Owner and End User, while vendors demonstrated agile collaboration, user-centered design, content writing, and CMS configuration.

Each team could bring up to six participants and had to provide their own equipment, including internet access. This prevented technical disruptions from being the government's responsibility. Each TCD was held separately to keep evaluations fresh.

At the end of the demo, vendors submitted a private Git repository with source code, documentation, a public prototype URL, an admin panel, and access to any tracking tools (e.g., JIRA). Supporting artifacts (like user stories, test plans, and whiteboard images) were also uploaded to reflect their real development process.

## Initial Best Value Determination

Once the TCDs were complete, the Government created a Comparative Analysis Evaluation document where a comparison was made between each Offeror’s Written Technical Solution and TCD. This document, along with the final Price Evaluations, was used to determine the Best Value proposal which was documented in a Comparative Analysis Decision Document (CADD) which was signed and included in the award file.

## Negotiation of Final PWS and Deliverables

After identifying the apparent awardee, the Government requested a final Performance Work Statement (PWS) and any needed updates to the Schedule of Deliverables, aligned with the vendor’s proposed approach. Minor changes were made and incorporated into the final award. Vendors had been advised that if these changes affected the technical approach or price, the Government could reconsider the award decision. In this case, no such changes occurred, and an addendum was added to confirm the decision remained unchanged.

## Lessons Learned

The process was successful in selecting a highly capable vendor for a complex, high-profile project. However, several lessons emerged:

* **Sequence Matters:** When time allows, review written technical solutions before the TCD to avoid unnecessary vendor effort, especially for those unlikely to win. A formal cut-down step or multi-step advisory process (FAR 15.202) can help.
* **Government Evaluator Expertise:** Ensure TCD evaluators have strong technical backgrounds to fairly and accurately assess capabilities.
* **Clear Criteria:** With a SOO, align expectations across government and vendors. Differing interpretations can hinder fair comparison of technical approaches.
* **Supporting New Vendors:** Innovative methods may attract non-traditional vendors, but they may lack familiarity with federal norms. Use plain language and be explicit in instructions to level the playing field.
* **Keep It Lean:** TCDs are effective but resource intensive. Consider simpler alternatives like submitted artifacts when appropriate to reduce cost and burden.
* **Post-Award Feedback:** After debriefs and protest windows close, informally ask vendors for feedback. Their insights can improve future procurements.

## Bottom Line

Both the Government and vendors viewed the process positively and encouraged continued use of similar methods. The Case Study helped quickly narrow the field with minimal vendor burden. The short, focused Written Approach avoided lengthy, boilerplate responses, and the live demonstration provided a clear view of actual capabilities, saving time and avoiding 50-page technical volumes. Comparative Analysis lets us evaluate diverse approaches without rigid scoring formulas. The entire process—from acquisition package to award—was completed in just six weeks, proving that a streamlined, innovative approach is not only effective, but fully compliant with the FAR.

