# Strategy Table in Practice

**Introduction: Aligning Acquisition Strategy with Digital Maturity**

As federal agencies and programs evolve in their adoption of digital service practices, acquisition strategies must be calibrated to meet both current capabilities and aspirational goals. This Maturity Table serves as a strategic guide to help acquisition professionals tailor their approach based on an honest assessment of their organization’s maturity level—Novice, Intermediate, or Expert—in implementing modern digital services.

This tool is not a prescriptive checklist, but rather a flexible framework that empowers teams to make informed decisions on key elements such as requirements documentation, trust dynamics with contractors, team composition, delivery pace, contract structure, and success metrics. Whether initiating a new agile pilot or scaling established practices, the table supports intentional, evidence-based planning for digital acquisitions.

Users are encouraged to begin by assessing their maturity level, then selecting the appropriate strategies across each acquisition component. The table also provides real-world examples and references from the TechFAR Hub, helping teams connect theory with practice.

Ultimately, this guide helps agencies avoid overreach or underutilization, promoting right-sized, mission-aligned digital delivery contracts that grow capability over time.

## Maturity table
This table represents a quick reference for developing an appropriate acquisition strategy based on the level of maturity in adopting digital service techniques within your agency or office. As every acquisition is unique, this is a guide not a directive.

|  | Novice | Intermediate | Expert |
| :---- | :---- | :---- | :---- |
| Best example on TechFAR Hub | Initiatives: [8(a) Learn the Process SOO](https://usds.github.io/techfar-hub-v2/initiatives/8a/) | Samples: [Agile Development RFQ Sample](https://techfarhub.usds.gov/resources/templates-samples/) | Case study: [VA Claims Appeals System](https://techfarhub.usds.gov/resources/case-studies/va-modernize-claims-appeals/) |
| What requirements document to use | Statement of Objective | Statement of Objective or Performance Work Statement | Statement of Objective /Performance Work Statement/ Statement of Work |
| Trust factor between Gov \+ contractors | Build together through baselining/delivery | Established at contract kickoff meeting | Inherent from first communications throughout the solicitation \+ acquisition |
| Team composition: Gov’t to contractor blend | High contractor blend for majority of work: Government provides these roles: COR, Product Owner, and stakeholders | Moderate to high level of contractors providing majority of work: Government provides: COR, PO, Stakeholders, UX, UI, some Dev | Blended team environment with potentially equal blend of Government and contractor with equal skill sets. |
| Implementation pace | Slow/Methodical to get baseline velocity established | Ramps up quickly to full optimization | Hits the ground running |
| Initial POP recommendation | Minimum 3 months – max 1 year | 6 months- 1 year | 1 year \+ options |
| How success is determined | End users of system happy with outcomes; program team understands how/why success was achieved | End users happy; program team and stakeholders see demonstrated value delivered | End users happy; program team & stakeholders see demonstrated value delivered; Gov’t Designers/Product Owners/Devs/Engs have confidence in delivery practices/process |
| How to validate vendor’s proposals in solicitation | Past success in delivering product in bureaucratic environment (commercial or federal). Solution provides the “HOW” for the implementation. | Past success, describe How, and some measure of validation (orals, scenario based response, due diligence) | Past success, body of work (github repos, portfolio), coding challenges |
| General pace of delivery | Slower delivery, best practices forming | Continual release of working product, optimization occurring with teams and program | Rapid \+ continuous development and implementation |
| Contract type | T\&M/Labor Hour for baselining with plan to convert and define FFP for future tasks | FFP per iteration | T\&M if government/contractor team is blended. FFP per iteration |
| Key personnel | Not recommended | Certain roles potentially | Certain roles potentially |
| Incentives | None, Award term, Past Performance | Award Term, Past Performance, Incentive or Award Fee | Past Performance, Award Term |

### How to use the table in practice

**Step 1: Assess the Maturity of the Agency or Program**
* Consider team staffing, history with agile projects, comfort with modular contracts, and technical capacity.  
* Self-assess or facilitate a maturity discussion to place the program in Novice, Intermediate, or Expert.

**Step 2: Use Rows as Strategic Building Blocks**
* Each row offers a guideline for how to shape a specific part of the acquisition strategy.  
* Read across the row and select the approach that aligns with the maturity level assessed in Step 1\.

**Step 3: Build the Acquisition Plan**
* Use the strategies in the selected column to build your:  
  * Acquisition milestone plan  
  * Requirements format  
  * Evaluation approach (e.g., oral presentations, code samples)  
  * Contract type and structure  
  * Delivery expectations and cadence

**Notes:** 
* This table is not linear. You don’t have to move through Novice → Expert. It’s about the current context.  
* Agencies can use this to negotiate better with stakeholders who may overestimate (or underestimate) their digital readiness.  
* When in doubt, encourage starting small (Novice) and iterating forward.

### Strategic framing questions element

| Factor | Framing Question |
| ----- | ----- |
| Requirements document to use | Do we know enough about the problem and solution to write detailed requirements, or should we use a more flexible format like an SOO? How much responsibility are we going to take on for the outcome? |
| Trust factor between Gov \+ contractors | How much existing trust or collaboration experience do we have with industry partners? Will trust need to be built during the project? |
| Team composition: Gov to contractor | What technical roles are staffed within the government team, and where do we need contractor augmentation? Are we ready to work as a blended team? |
| Implementation pace | How quickly can the agency adapt to iterative delivery? Do we need a slower onboarding period to establish baselines or train internal staff? |
| Initial POP recommendation | How long do we expect it to take to show value, onboard vendors, and ramp up delivery? Are we setting the team up for success with enough time? |
| How success is determined | How will we know this contract is successful? Is success defined by delivery outcomes, end user feedback, or internal process improvements? |
| How to validate vendor proposals | What evidence do we need to see that a vendor can deliver this type of work? Can we evaluate based on real-world examples, orals, or technical artifacts? |
| General pace of delivery | What is our expected delivery cadence? Are we prepared for weekly releases or do we need slower cycles to manage change? |
| Contract type | What level of flexibility do we need in budgeting and delivery? Can we handle a T\&M structure or should we use fixed-price per iteration? |
| Key personnel | Do we need to specify key roles in the contract to ensure continuity or quality in delivery? Why do we need them and are we confident we can identify the right roles in advance? |
| Incentives | Should we include incentives to drive performance, retention, or risk-sharing? What kind of reward structures would best motivate the vendor? |
