# Welcome to the DITAP Vendor Playbook 

This playbook is here to help you deliver the refreshed Digital IT Acquisition Professional (DITAP) program with clarity, confidence, and consistency. The DITAP program is a multi-modal training and development experience delivered over months at a time, built around a cohort-based learning approach that emphasizes collaboration, peer learning, and practical application. Inside, you will find the program structure, key requirements, competency-based content, and essential learning activities, along with tips, tools, and examples to make facilitation smoother and more engaging. While it provides a clear framework to ensure a high-quality experience for every cohort, it also leaves room for you to adapt delivery to your style and your learners’ needs. Think of it as both a guide and a partner, supporting you from planning through delivery so together we can create impactful learning experiences that prepare participants to succeed in real-world acquisition environments.

## Program overview

The Digital Services Credential (DITAP), formerly FAC-C-DS, program aims to train and develop professionals for this certification, focusing on digital service acquisition. It requires a comprehensive approach that includes pre and post-course assessments, multi-modal training delivery utilizing a learning management system, and evaluation based on participation, mastery of content, and a live digital assignment. The program emphasizes a cohort-based learning approach which can be both in-person or fully remote for the majority of facilitation or the majority of content. The curriculum, structured in modules and sprints, covers competencies such as understanding digital services, effective buying techniques, contract administration, and leading change in digital IT acquisition, with the goal of providing participants with practical skill development through real-world application and problem-solving. 

## Program structure

The DITAP program is organized to guide participants through a progressive learning journey that blends knowledge building with hands-on application. Its structure combines sequential modules, practical activities, and applied projects in a way that reinforces learning over time. The design ensures that each topic builds on the last, moving participants from understanding core concepts to confidently applying skills in real-world acquisition scenarios.

### Core design principles for delivery

- **Cohort-based learning:** Participants move through the program together, building peer networks, sharing perspectives, and supporting each other’s growth. This sustained engagement is key to the program’s success.
- **Blended, multi-modal delivery:** Learning takes place through a mix of live facilitation, online modules, group discussions, and hands-on assignments.
- **Technology-enabled experience:** Vendors must use a learning management system (LMS) to host course content, track progress, and facilitate discussions. Webinars and other collaboration tools, such as discussion boards or shared workspaces, should be used to enhance interaction and access.
- **Integrated assessment:** Progress is measured through pre- and post-program assessments, active participation, demonstrated mastery of content, and successful completion of a live digital assignment (LDA).
- **Anchor learning in real work**: Use the case study, threaded activities, and Live Digital Assignment to give participants realistic scenarios where they can apply new skills in their own agency context.

### Program modules

The program is divided into five modules, each with multiple sprints that serve as subtopics within the module. These sprints break the content into focused segments, allowing participants to explore specific concepts in depth while building toward the module’s overall learning objectives. The five modules are:

1. **Describe**: Explore what digital services are, who provides them, how they are delivered, and why they are important. Includes an overview of delivery methods (Agile, Human-Centered Design, DevSecOps) and a “Tech Bootcamp” covering data, software, cloud, AI, security, accessibility, and open source.
2. **Discover**: Learn how to assess agency readiness, map stakeholders, define success, and conduct effective market research to inform acquisition strategies.
3. **Design**: Translate discovery insights into a structured solicitation. Covers acquisition strategy development, solicitation creation, and evaluation planning.
4. **Build**: Manage vendor partnerships and guide delivery using Agile and lean principles. Topics include performance measurement, kickoff facilitation, and problem resolution.
5. **Grow**: Strengthen the ability to lead change and foster innovation at both the individual and organizational level.

### Target audience

- Required: FAC-C (Professional) holders with at least two years of experience in digital service acquisitions over the FAR 13.500(c) threshold.
- Encouraged: FAC-COR Level II/III and FAC-P/PM Level II/III holders with similar experience, especially those working in cross-functional teams.

## Applicant selection

Selecting the right participants is essential to creating a dynamic learning environment and achieving the program’s intended outcomes. While the DITAP program includes formal eligibility requirements, vendors are encouraged to view applicant selection as an important step in shaping the cohort experience. Thoughtful selection can help ensure that participants bring a mix of relevant experience, motivation, and openness to learning, which in turn supports deeper engagement, richer discussions, and more meaningful application of skills back in the workplace.

### Minimum requirement

For questions regarding minimum requirements and eligibility criteria, please refer to the "Who can enroll in the DITAP program?" section in the TechFarHub.

### Recommended screening process

Although not required, vendors are encouraged to implement a screening process to assess fit for the program. This can include reviewing application responses, conducting brief interviews, or seeking input from the participant’s supervisor. The goal is to ensure each participant is ready and able to engage fully in the cohort experience.

### Attributes of an ideal candidate

An ideal participant will typically:

- Demonstrate a willingness to experiment, share knowledge, and collaborate with peers.
- Show commitment to applying new skills in their role rather than attending simply to complete a requirement.
- Work in an organization that supports applying the DITAP certification in practice after program completion.
- Have an interest in digital service acquisition, even without a formal IT background.
- Exhibit a positive, change-oriented mindset while acknowledging the realities and challenges of technology acquisition in government.

## Orientation - course start

A strong program launch sets the tone for the entire learning experience. Orientation is an opportunity to establish the cohort community, build connections among participants, and provide a solid foundation for the content to come.

### Optional enhancements

- Cohort Connection: Orientation must be delivered in person to foster a sense of community among participants and reinforce the cohort-based nature of the program.
- Introduction to Agile: A hands-on “Introduction to Agile” activity is required to give participants—especially those without a digital services background—a clear understanding of agile concepts and practices. This can be achieved through experiential exercises such as Play-Doh or LEGO simulations, or other interactive activities that make agile principles accessible and memorable.
- Icebreaker activities
- Guest speakers from government or industry
- Additional activities or topics tailored to the cohort’s needs

### Supporting materials

Orientation materials from the DITAP Refresh are provided in the Refresh GitHub Repo.

## Graduation - course end

Graduation is an opportunity to recognize participant achievement, celebrate the learning journey, and reinforce the value of applying skills back on the job. While not required to be in person, a meaningful closing event can help sustain momentum and strengthen the alumni network.

### Required elements

- **Continuous Learning Points (CLPs):** Participants are eligible to receive 60–80 CLPs based on the delivery approach. Vendors must clearly state in the course materials the total CLPs that can be earned and how they are awarded.
- **Certificate of Completion:** Each participant must receive a training certificate including:
  - Course title
  - Full dates of the course
  - Participant’s full name
  - Name of the organization conducting the training
  - Number of CLPs earned
- **Graduate reporting:** Vendors must submit a final list of all certificate holders to USDS at <techfarhub@omb.eop.gov> so they can be added to the DITAP Alumni listserv.  

### Optional enhancements

- Guest speakers from government or industry
- Special recognition events or activities to mark completion

### USDS review  
USDS will review the CLP distribution approach, certification format, and graduation activities, whether in person or virtual.

**Supporting materials**
A sample certificate format is included in the [Appendix](url).

## DITAP delivery: required and optional components

To support consistency across all DITAP deliveries, the following section identifies which elements of the program are required versus those that are optional. Required elements form the foundation of the program and ensure participants meet the learning outcomes set by USDS. Optional elements provide flexibility for vendors to enhance delivery with activities and assessments that best fit their facilitation style, participant needs, or agency context. Assignment timelines are flexible based on vendor delivery needs; however, all assignment requirements must be met and participants must complete each assignment as instructed.


| **Program Element** | **Required / Optional** | **Notes** |
| --- | --- | --- |
| Self-Paced Content | **Required** | All core self-paced modules must be delivered and may be adapted as long as it meets the need of the learning objectives. Vendors may add supplemental materials, including images, video or audio files, charts and resources, to support the learning requirements; however, no content may be removed.|
| Activities (ILT or exercises) | Optional | Vendors may select or adapt activities to support facilitation style. |
| Applied skills assignments | **Required** | Includes shadowing, stakeholder activity, and live digital assignment. Vendors may add supplemental materials to support the learning requirements; however, no content may be removed. |
| Threaded case scenario | **Required** | Must be integrated across modules. Vendors may add supplemental materials to support the learning requirements; however, no content may be removed. The threaded case study may be replaced with an alternate case study, provided it remains structured as a threaded case study. |
| Pre- and post-surveys | Optional | Vendors may administer as part of evaluation, not mandatory. |
| Pre- and post-assessments | **Required** | A pre and post assessment must be administered. Vendors have the flexibility to adapt and adjust the choice of assessment as needed. You may add suplemental materials to support the learning requirements; however, no content may be removed. |

---

## Assessment and Grading Guidance

### Overview

The DITAP refresh reimagines assessment strategy to reflect modern adult learning principles. Rather than checking boxes, assessments build confidence through practice, feedback, and reflection while helping learners apply course concepts to real-world work.

Our assessment design is grounded in [The Learning-Transfer Evaluation Model](https://github.com/usds/ditap-curriculum-update/edit/thesarahbaron-patch-13/3_Curriculum/3A_DITAP-Core-Curriculum/1_Vendor-Materials/Vendor%20Playbook/Vendor%20Playbook.md#the-learning-transfer-evaluation-model-ltem-alignment- (LTEM)), which moves beyond attendance and knowledge recall to measure decision-making, performance in realistic settings, and the foundation for on-the-job transfer and organizational impact.

**Vendor Flexibility**: Vendors have discretion to adapt their assessment strategy to their delivery format, learner needs, and agency-specific contexts while maintaining DITAP's core learning objectives.

---

### Pass/Fail structure

DITAP uses a pass/fail approach that encourages learners to focus on growth, collaboration, and real-world application rather than point accumulation. This mirrors the real-world environments they'll operate in.

### Requirements for completion

To successfully complete DITAP and earn a certificate, vendors must assess two areas:
1. **Participation** – Meaningful engagement in course sessions as measured by the provided rubric
2. **Conceptual Fluency**– Understanding and application of key DITAP tools and frameworks through applied learning assignments and pre vs. post assessment comparison.

### Progress indicators

Without formal grades, students need regular feedback to ensure they're on track. Use these indicators:

**On Track to Pass**

- Consistently contributes in discussions (see rubric)
- Accurately applies frameworks in assignments, no revisions required
- Completes all phases of the capstone project
- Demonstrates growth in post-assessment results

**May Be At Risk**

- Rarely participates (multiple "needs attention" ratings)
- Misses key deliverables
- Struggles to apply frameworks in assignments; revisions are required
- Shows little to no progress from pre- to post-assessment

---

## Participation assessment

### Participation rubric

The  rubric evaluates three dimensions of engagement: 

|     | **Fully Engaged** | **Progressing** | **Needs Attention** |
| --- | --- | --- | --- |
| **Cohort Contribution** | Consistently contributes in live sessions; builds on others' ideas; prepared and engaged | Occasionally contributes; listens actively; sometimes prepared | Rarely participates or comes unprepared |
| **Connections** | Frequently connects course content to real work; shares relevant examples | Makes occasional connections between course and work | Struggles to relate content to context |
| **Emergent Thinking** | Regularly introduces new perspectives; demonstrates curiosity and depth | Sometimes surfaces thoughtful ideas | Rarely explores beyond surface-level |

## Participation assessment implementation
_Timing: During/after interactive sessions, especially those tied to the threaded case scenario._

| **Type of Assessment** | **Description** | **Suggested Cadence** | 
| --- | --- | --- |
| Participant self-assessment | Using the rubric, learners reflect on their own engagement and identify one area for growth. | Once per module | Rarely participates or comes unprepared |
| Assessment by peers | Pairs or small groups provide one observation and one suggestion using rubric. | Twice per course |
| Assessment by facilitators | Instructors use the rubric to guide individual or group feedback after observed sessions. | Twice per course | 

### Intervention guidance

Schedule a facilitator check-in when a participant meets either criterion:

- Two consecutive "Needs Attention" ratings in the same dimension, OR
- Three total "Needs Attention" ratings across any dimension during the program

Use the rubric to guide conversations and offer concrete re-engagement strategies.

---

## Conceptual fluency assessment

Conceptual fluency is the ability to understand, apply, and clearly communicate key DITAP tools and frameworks (Digital Services Playbook, TechFAR, human-centered design principles) in realistic work contexts.

### Assessment components

#### Pre- and post-course assessments

- **Pre-Assessment**: Informational and diagnostic only. Establishes baseline understanding and helps vendors identify instructional emphasis areas.
- **Post-Assessment**: 80% required for pass/fail determination. Confirms minimum conceptual fluency for DITAP framework mastery.

  - Multiple attempts allowed
  - After first failure, redirect to challenging sections of schedule facilitator check-in.
  - After multiple failures, provide additional interventions (peer coaching, office hours, targeted practice).

<br>

### Applied learning assignments

- Stakeholder Research Assignment
- Shadowing Assignment
- Live Digital Assessment (LDA)

<br>

**Stakeholder research and shadowing assignments**

- Specific instructions for what constitutes passing are provided in dedicated playbooks [link to playbooks]
- In short, both assignments have two phases:
  - Phase 1: Requires approval to proceed
  - Phase 2: Requires passing grade for completion

 
**Live Digital Assignment (LDA)**

- DITAP's capstone experience simulating the complete lifecycle of a digital services acquisition
- Participants apply key DITAP concepts in real-world context through four phases:
  - Discovery Sprint
  - Case Study Development
  - Peer Evaluation
  - Final Presentations
- The Case Study Package is assessed as a **gated Pass/Fail**, meaning learners must pass to continue. All phases are essential for learning and completion and pass/fail criteria are provided for each phase in the LDA playbook. [link to LDA playbook]


### Knowledge checks

Embedded throughout self-paced modules to help learners identify misconceptions early and practice key concepts. While successful completion isn't required for advancement, vendors must track participation and performance patterns to guide facilitation and support.

---

## Continuous Learning Points (CLPs)

Participants in the full 6-month DITAP program should be eligible to receive 80 CLPs upon successful completion of all program requirements.

For shorter or adapted versions of the program, training providers should work with USDS to determine the appropriate CLP allocation. The total number of CLPs and the criteria for earning them should be clearly stated in the course materials provided to participants.

---

## The Learning-Transfer Evaluation Model (LTEM) Alignment<a id="The Learning-Transfer Evaluation Model (LTEM) Alignment"></a>

DITAP assessments are intentionally designed using the Learning-Transfer Evaluation Model (LTEM), created by Will Thalheimer. LTEM provides a framework for measuring learning effectiveness beyond attendance or satisfaction surveys, progressing from basic measures of participation and engagement (Levels 1–3) to deeper measures of knowledge, decision-making, and performance (Levels 4–6), and ultimately to transfer and organizational results (Levels 7–8).

### LTEM levels in DITAP

| **LTEM Level** | **Description** | **DITAP Examples** | 
| --- | --- | --- |
| 1. **Participation** | Learners are present for live sessions and complete required self-paced modules. | Zoom attendance logs; LMS completion records; average learning time. |
| 2. **Engagement** | Learners actively engage with required learning activities and assignments. | Time spent in lessons; whether videos are watched in full vs. fast-forwarded; frequency and quality of questions asked during live sessions; self-paced knowledge check completion; assignment submission (before feedback). |
| 3. **Learner perceptions** | Learners report the relevance, quality, and effectiveness of the course. | End-of-course survey; mid-course pulse check; reflections on perceived skill growth and confidence. |
| 4. **Knowledge** | Learners recall and accurately describe key facts, terms, and frameworks tied to course outcomes. |Knowledge checks in self-paced modules; accurate use of terminology in class; conceptual fluency demonstrated during discussion and assignments.|
| 5. **Decision-making** | Learners choose appropriate actions or solutions in realistic scenarios. |Responses in the threaded case scenario; scenario-based knowledge checks; decision-making prompts in live sessions; conceptual fluency shown when weighing trade-offs or justifying choices.|
| 6. **Performance (in learning environment)** | Learners demonstrate skills effectively in realistic but low-risk practice settings. | Conducting stakeholder interviews; applying HCD tools in problem-framing exercises; delivering LDA case study presentations; all applied learning. |
| 7. **Transfer (on the job)** | Learners apply new skills and approaches in their real work environment. | [Assessed post DITAP, Consortium to own] Alumni survey 30–60 days post-course asking for specific examples; Best practice: manager interviews to confirm observed behavior changes. |
| 8. **Results** | Tangible, measurable organizational or mission-level improvements linked to the learning. | ((Assessed post DITAP, Consortium to own))  Agency reports of faster procurement cycles, cost savings, improved collaboration, or time savings tied to DITAP graduates; documented ROI of learning initiatives. |

<br>

### Progressive skill building

This structure creates scaffolded learning:

- Participation and early activities establish engagement and basic knowledge.
- Knowledge checks and applied assignments provide low-stakes decision-making practice.
- Capstone project demonstrates comprehensive performance ability in realistic conditions.


### Beyond the course

LTEM Levels 7 (Transfer) and 8 (Organizational Results) are assessed after course completion, and the DITAP consortium is actively working on measurement strategies for these levels. Level 8 represents the gold standard of organizational impact but may be challenging to achieve given agency constraints and the multiple factors beyond DITAP training that influence organizational outcomes. Successful completion of DITAP's assessment structure positions participants to achieve these higher levels after the program concludes.

<br>

## Implementation requirements summary

Each vendor must implement an assessment plan that includes:
1. Meaningful participation measurement using engagement rubrics with ongoing feedback opportunities
2. Consistent conceptual fluency measurement across multiple elements:
    - Pre-course and post-course assessment administration
    - Embedded knowledge checks in self-paced learning
    - Applied learning assignments (shadowing, stakeholder research)
    - Cumulative capstone project simulating real-world digital acquisition challenges

Vendors may supplement with additional assessments based on delivery format, learner preferences, or agency-specific contexts.

---

## Sample Communications


### “Participation Needs Attention” email template

<br>

**Subject:** Quick check-in on participation

Hi \[Student Name\],

I wanted to touch base about your participation in the DITAP course. Based on recent reflections and observations, it looks like your participation in the course needs attention. As you know, participation means contributing to discussions, connecting course material to your day-to-day work, and surfacing emerging insights. When those opportunities are missed, it becomes harder to get the full value of the course.

This isn't about being the most vocal person—it's about showing up in ways that support your learning and the group's. I'd love to help you get more out of the rest of the course. If you're open to it, let's connect and talk through what might help.

Warmly, \[Facilitator/Vendor Name\]

<br>

### Sample reflective coaching prompts

- What's one way you've contributed to others' learning in the course so far?
- What connections have you been making between this session and your work?
- What's one question or insight you want to keep exploring?

<br>

---

## Module Content Overview

## Module 0: Orientation


| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Program Overview and Navigation** | This topic provides an overview of the DITAP training program, including its structure, learning objectives, and key curriculum components. Learners will gain clarity on how the course is organized, what to expect from each module, and how the program supports their development as digital service acquisition professionals. | N/A |
| **Learning How to Learn** | This topic introduces the principles of adult learning and the mindset needed for success in an applied, collaborative training environment. Learners will explore strategies for managing time, workload, and personal growth as they engage with hands-on activities and peer-driven discussions throughout the course. | Develop an understanding of how adult learning principles, personal learning strategies, and mindset shifts support success in a collaborative, experiential course environment. |

### Topics
- Structure of the DITAP program  
- Learning objectives and competencies  
- Key curriculum components and modules  
- How to navigate course materials and resources  
- What to expect from program pacing and delivery  
- Principles of adult learning  
- Mindset for success in a collaborative environment  
- Strategies for time and workload management  
- Approaches to personal growth and reflection  
- Making the most of hands-on activities and peer discussions  

---

## Module 1: Describe

Describe: Explore digital services in the 21st century, including what they are, who provides them, how they are delivered, and why they are important.

## Sprint 1: The Digital Services Landscape

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **What is Digital Service?** | This topic introduces the foundational concepts of digital services within the federal landscape. Learners will recognize key characteristics of digital services, explore common examples in government, and build a basic understanding of the underlying systems and architecture that support their delivery. | Define digital services and the problems they can be used to solve. |
| **Digital Services in Government** | This topic introduces key players in the digital services ecosystem, both within government and in the private sector. Learners will identify major organizations and roles involved in digital service delivery and explore foundational resources such as the U.S. Digital Services Playbook and the TechFAR Handbook to understand their relevance to federal procurement practices. | Identify "who's who" in the digital services arena, including public and private sector organizations and individuals; Identify and understand the Digital Service Playbook and TechFAR Handbook concepts. |

### Topics 
- Digital Services - The Who and What  
- Then and Now: USCIS.gov Use Case  
- Defining Digital Services: Another Take  
- The Digital Services Ecosystem  
- The Digital Services Ecosystem, Part 2  
- Who’s Who: A Starting List  
- Activity Break (Optional)  
- Recommended Readings  
- Case Study Tie In: Module 1 Activity: Introducing Casey and the CRM Project

## Sprint 2: Digital Service Methods, Roles, and Sources of Supply

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Digital Service Delivery Methods 1: Agile** | This topic introduces agile software delivery as a foundational approach to modern digital services. Learners will compare agile and traditional (waterfall) development methods, explore core agile principles, and examine key team roles, ceremonies, and practices that enable iterative and user-centered delivery. | Identify modern design, development, and delivery methods used by digital services professionals. |
| **Digital Service Delivery Methods 2: Design / User-Centered Design / DevSecOps** | This topic explores complementary practice areas that strengthen agile digital delivery. Learners will examine user-centered design, DevSecOps, and related private sector practices that contribute to secure, iterative, and user-focused software development in government contexts. | Identify modern design, development, and delivery methods used by digital services professionals. |
| **Digital Service Delivery Providers: Sources of Supply** | This topic provides an overview of the current landscape of digital service providers. Learners will identify key government-led digital service organizations and understand how private sector vendors contribute to delivery. The topic also introduces sourcing considerations relevant to federal acquisition professionals evaluating potential partners. | Identify "who's who" in the digital services arena, including public and private sector organizations and individuals. |

### Topics 
- Digital Services – The How (Introduction)  
- Learn About Your Users’ Needs  
- Learn About Your Users’ Needs (Cont'd)  
- Contemporary Practices in Developing Digital Services  
- Digital Service Delivery Methods: Agile  
- Digital Service Delivery Methods: HCD and DevSecOps  
- Activity: Create a Sprint Backlog  
- Digital Service Delivery Providers: Sources of Supply  

## Sprint 3: Digital Service Tech Bootcamp

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Introduction to Digital Service Tech Bootcamp** | This topic provides a high-level overview of the core technologies behind digital service delivery. Learners gain foundational awareness of data, software, cloud, AI, and cybersecurity to better understand technical proposals and engage with digital service teams during the acquisition process. | Identify and describe core technology domains that underpin digital service delivery, including data, software, cloud computing, AI, and cybersecurity. |
| **Tech Topic 1: Data** | This topic introduces the role of data in digital service delivery. Learners will exploredifferent types of data, how data is stored, shared, and managed within government systems, abd the importance of open data, privacy, and security. Key considerations related to data lifecycle management and compliance will also be discussed. | Explain key concepts related to data in digital services, including data types, storage, sharing, open data, privacy, and compliance considerations. |
| **Tech Topic 2: Software** | This topic examines the software landscape in government procurement, including commercial software COTS and SaaS), custom software development, and delivery models. Learners will identify key roles in software delivery, understand software acquisition considerations, and explore relevant policy areas that shape buying decisions. | Identify modern software design, development, and delivery methods used by digital service professionals, and describe key acquisition considerations across COTS, SaaS, and custom solutions. |
| **Tech Topic 3: Cloud** | This topic provides an overview of cloud computing in the federal environment. Learners will explore different types of cloud services, benefits and challenges of cloud adoption, and the policy frameworks that govern cloud usage in government digital service delivery. | Explain the benefits, challenges, and types of cloud services, and describe relevant policies that shape cloud adoption in government. |
| **Tech Topic 4: AI** | This topic introduces learners to the current landscape of AI tools and models used in digital services. Learners will examine foundational concepts, applications in government, and key policy issues such as transparency, bias, privacy, and responsible AI use. | Describe the current landscape of AI tools and models, and explain key policy considerations including transparency, bias, and responsible use. |
| **Tech Topic 5: Security** | This topic explores essential principles of cybersecurity in digital service delivery. Learners will review concepts such as identity and access management (IAM), vulnerability management, continuous monitoring (e.g., SIEM), and compliance frameworks. The topic also connects these principles to relevant federal policies and acquisition considerations. | Identify foundational cybersecurity concepts such as IAM, vulnerability management, and compliance frameworks, and explain their relevance to digital service delivery. |
| **Tech Topic 6: Accessibility** | This topic explores essential concepts of accessibility in digital service delivery, emphasizing its importance in federal procurement. Learners will examine how accessibility ensures digital products and services are usable by all individuals, including those with disabilities, and how it benefits a wider audience such as seniors and veterans. The topic also covers common misunderstandings, the integration of accessibility throughout the acquisition lifecycle, key laws and standards like Section 508 and WCAG 2.2, and available tools and templates to improve accessibility outcomes in procurement. | Recognize the essential concepts of accessibility in digital services procurement, Identify common misunderstandings about accessibility and how to address them, Recognize the importance of ongoing accessibility maintenance throughout a project's lifecycle, Use federal tools and templates to improve accessibility outcomes in your procurements. |
| **Tech Topic 7: Open Source** | This topic introduces procurement officers to the principles, risks, and opportunities of open source software (OSS) in digital government. It covers how OSS reduces costs, increases innovation, and supports vendor independence. Key areas of discussion include legal foundations, evaluation practices, and the role of OSS in long-term service delivery and transparency, addressing common misunderstandings and its integration into the acquisition lifecycle. | Recognize how open source software fits within federal procurement, Identify common myths and misunderstandings around OSS in government, Explain how open source software fits into Commercial Off-the-Shelf (COTS) procurement. |

### Topics
**Tech Topic 1: Data**  
- What is data?  
- Key considerations for government systems
- Open Data
- Data privacy  

**Tech Topic 2: Software**  
- What is software?
- How is software developed?
- How is software delivered?
- How is software updated?
- Considerations around supply chain licensing
- Service design and delivery standards  

**Tech Topic 3: Cloud**  
- Basics
- Considerations
- Why understanding Cloud Computing is critical for government contracting officers
- Bottom line for contracting officers  

**Tech Topic 4: AI**  
- What Is Artificial Intelligence?
- Types of AI
- Key considerations for government systems
- Common AI terms you may encounter
- Why it matters to procurement officers
- "What contracting officers should keep in mind"  

**Tech Topic 5: Security**  
- Why is cybersecurity important?
- Cybersecurity in the current federal procurement context
- Four key areas of cybersecurity for digital services  

**Tech Topic 6: Accessibility**  
- Must-know concepts
- Common misunderstandings
- Where does accessibility show up?
- Key laws, standards, or frameworks  

**Tech Topic 7: Open Source**  
- Must-know concepts
- Common misunderstandings
- Why OSS shifts power back to government
- How open source shows up in the acquisition lifecycle
- Key laws, standards, or frameworks  


---

## Module 2: Discover

Discover: Engage in a discovery process to set the foundation for informed acquisition strategy decisions. By assessing organizational maturity, identifying key stakeholders, analyzing mission and user needs, evaluating risks, and performing market research, you will gather the data necessary to shape a successful digital service procurement.

## Sprint 1: Assessing Agency Readiness

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Assessing Agency Readiness** | This sprint introduces tools and strategies to evaluate an agency’s readiness to pursue a digital service procurement. Learners will assess internal capacity including staffing, technical expertise, and leadership alignment while using frameworks such as the digital service maturity matrix to identify areas of strength and improvement. | Assess your agency’s capacity, maturity, and alignment to support a successful digital service procurement. |

### Topics
- Introduction to assessing agency readiness  
- Determine your organizational maturity  
- Strategy table in practice  
- Change and Innovative Readiness Survey introduction  
- Change and Innovative Readiness Survey (in class / fillable)  

## Sprint 2: Stakeholder and Customer Mapping

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Stakeholder and Customer Mapping** | This sprint focuses on identifying and engaging the individuals and groups who influence or are impacted by a digital service procurement. Learners will differentiate between stakeholders, users, and customers, and begin mapping relationships to better align acquisition strategies with mission needs and user outcomes. | Identify key stakeholders, users, and customers relevant to your acquisition and analyze their roles, influence, and engagement needs. |

### Topics
- Navigating the stakeholder landscape: Introduction  
- Navigating the stakeholder landscape cont'd  
- Role play activity: Stakeholder influence challenge  
- Activity: Stakeholder analysis project introduction  


## Sprint 3: Defining Success for Your Digital Services Acquisition

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Defining Success for Your Digital Services Acquisition** | This sprint helps learners define what success looks like for a digital service acquisition. Learners will develop product visions, user stories, and outcome-oriented objectives to clarify mission needs. The sprint also introduces methods for identifying constraints such as policy, technology, or capacity that may impact delivery, and offers tools to frame success criteria beyond traditional compliance metrics. | Develop a shared understanding of your agency’s needs and constraints, and define success criteria for your digital service procurement. |

### Topics
- Defining success for your digital services acquisition overview  
- From discovery to strategy  
- Defining constraints before acquisition strategy begins


## Sprint 4: Conducting Effective Market Research

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Conducting Effective Market Research** | This sprint focuses on strategies for conducting meaningful market research in support of digital service procurements. Learners will explore how to assess industry capabilities, craft early needs statements, and apply research methods such as RFIs to inform acquisition planning. Emphasis is placed on minimizing burden to vendors while gathering actionable insights to shape a more responsive and competitive solicitation. | Apply effective market research strategies to assess vendor capabilities and inform your digital acquisition approach. |

### Topics
- Introduction to conducting effective market research  
- Introduction to building your market research toolkit
- Acquisition toolkit worksheet
- The Magic Quadrant
- Responsible pre-solicitation communication
- Acquisition process myths
- Why pre-solicitation communication matters
- Knowledge check
- How to communicate effectively
- How to communicate effectively: Step 2
- Engaging the industry traditionally
- Activity: Signal or noise? Evaluating RFIs with AI insight
- How to communicate effectively: Step 3
- Understand the cost-benefit and tradeoffs
- Conclusion: Leveraging HCD and AI in federal market research 

---


## Module 3: Design

Design: Translate your discovery findings into a well-structured solicitation. Create acquisition strategy decisions around tradeoffs, evaluation processes, contract structure, and performance metrics which lead to the development of requirements, solicitation factors, and evaluation criteria that support user-centered outcomes and successful vendor partnerships.

## Sprint 1: Developing a Successful Acquisition Strategy

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Developing a Successful Acquisition Strategy** | This sprint guides learners through the key elements of developing a digital acquisition strategy. Topics include making informed build-versus-buy decisions, selecting appropriate procurement methods (e.g., OTAs, GWACs, 8(a), CSO), and structuring modular contracts to support iterative delivery. Learners will also examine contract types, performance-based incentives, outcome measurement tools such as burndown and velocity charts, and considerations related to data rights and long-term reuse. | - Identify how to apply flexibilities within the FAR to develop an acquisition strategy tailored for digital services.  <br> - Select appropriate evaluation methods and criteria related to cost, pricing, terms and conditions, cybersecurity, and data rights. <br> - Assess vendor maturity and capability to deliver a digital product based on defined needs and success criteria. |

### Topics
- Introduction: Developing an acquisition strategy  
- Why do we plan?
- What feeds the acquisition strategy?
- The acquisition plan lean canvas approach
- Common risks
- Contract exit strategies
- Stakeholder engagement: Capability and cooperation
- Existing contracts
- Streamline the process
- Considerations for a new contract
- Funding and programmatic considerations
- State of the market
- Compliance & other legal issues
- Getting to know your Office of General Counsel
- What is intellectual property?
- Types of IP
- FAR subpart 27.4 rights in data and copyrights
- Contribution, attribution, retribution...oh my!
- Who owns open source code?
- Data in the cloud (It's cloudy out there!)
- Legal liabilities
- What happens when open source software breaks?
- Case study tie in Module 3 activity: Solution evaluation with SWOT analysis
- Multi-vendor contracts


## Sprint 2: Developing the Solicitation

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Developing the Solicitation** | This sprint focuses on developing the core elements of a digital service solicitation to drive successful acquisition outcomes. Learners will explore how to write a Statement of Objectives (SOO), apply appropriate award procedures under the FAR and non-FAR authorities, and incorporate pricing strategies and evaluation language aligned with outcome-based delivery. The sprint also examines emerging considerations such as the role of AI in acquisition and the balance between key personnel and performance outcomes. | - Develop key elements of a digital service solicitation, including a Statement of Objectives (SOO), appropriate award procedures, and outcome-oriented evaluation factors. <br> - Evaluate how pricing structures, key personnel requirements, and emerging technologies such as AI may impact solicitation strategy and vendor response. |

### Topics
- Strategic planning and execution in digital acquisitions
- Developing a statement of objectives (SOO)
- Key sections of an SOO homework assignment (template)
- Understanding FAR 37.6: How does Agile methodology fit into federal acquisitions?
- Key personnel vs outcome-based
- Artificial intelligence and the acquisition strategy
- Discussion
- 7 strategies for evaluating the ethical and legal impact of implementing AI in federal agencies  


## Sprint 3: Running a Successful Evaluation

| Learning Elements | Descriptions | Learning Objectives |
| ---------------- | ------------ | ----------------- |
| **Running a Successful Evaluation** | This sprint prepares learners to run effective evaluations of vendor proposals in digital service procurements. Learners will explore how to define and apply technical evaluation criteria, select a skilled evaluation team, and use debriefing and negotiation techniques to support tradeoff decisions, strengthen vendor relationships, and ensure transparent, mission-aligned outcomes. | - Evaluate Agile vendors using solicitation criteria, oral presentations, and past performance to assess alignment with Agile practices and technical requirements. <br> - Design and apply evaluation strategies that incorporate down-selects, interactive techniques, and tradeoff approaches to support fair and best-value acquisitions. <br> - Deliver effective post-evaluation feedback that builds trust, strengthens future proposals, and aligns with FAR guidance. <br> - Conduct strategic vendor negotiations that clarify assumptions, manage risks, and secure best-value outcomes in digital service procurements. |

### Topics
- Evaluation criteria overview  
- Negotiating with vendors  
- Knowledge check  
- The power of debriefing

---

## Module 4: Build

Build: Manage vendor partnerships and support delivery through contract administration practices grounded in Agile and lean methodologies. Track project health using real-time, objective indicators, support continuous delivery, and adapt to change while ensuring alignment with mission goals. Focus on transparency, collaboration, and outcomes throughout the contract lifecycle.



## Sprint 1: Management of Digital Service Delivery

| Learning Elements | Descriptions | Learning Objectives |
| ----------------- | ------------ | ------------------- |
| **Management of Digital Service Delivery** | This sprint introduces key roles and practices that support effective post-award delivery of digital services. Learners will explore the function of product ownership, how product managers and contracting officer representatives (CORs) collaborate, and how Agile ceremonies and tools support iterative delivery. The sprint also emphasizes cross-functional team alignment and the importance of celebrating shared successes. | - Describe what product ownership looks like in federal digital service delivery environments. <br> - Explain how contracting officer representatives (CORs) and product owners (POs) collaborate to support Agile delivery. <br>  - Recognize the importance of communication, shared understanding, and Agile rituals in effective digital service teams. <br>  - Identify ways to celebrate progress and success across cross-functional teams. |

### Topics
- Managing digital service delivery  
- Amplifying Agile delivery  
- **Activity:** Who does what? Agile role round robin  
- **Activity:** Digital service project charter  

## Sprint 2: Performance Measurement Under Agile Delivery Contracts

| Learning Elements | Descriptions | Learning Objectives |
| ----------------- | ------------ | ------------------- |
| **Performance Measurement Under Agile Delivery Contracts** | This sprint explores how to measure performance in Agile digital service contracts using meaningful, real-time metrics. Learners will examine approaches that go beyond traditional compliance tools like the QASP, including milestone tracking, contractor self-reporting, CPARS, and quarterly performance reviews. The sprint also covers strategies for incentivizing outcomes and monitoring vendor performance in multi-vendor environments. | - Identify and apply performance metrics that help detect delivery risks or failure points early in Agile digital service contracts. |

### Topics
- Using value-based metrics and modern incentives in federal Agile procurement  
- Post-Award multi-vendor management  
- **Knowledge Check:** Managing a multi-vendor environment  
- Warranties in Agile development (Readings)  


## Sprint 3: Contract Kickoff

| Learning Elements | Descriptions | Learning Objectives |
| ----------------- | ------------ | ------------------- |
| **Contract Kickoff** | This sprint focuses on how to successfully launch a digital services contract. Learners will explore strategies for preparing both government and vendor teams, setting clear expectations, aligning on scope and delivery approach, and establishing communication and collaboration rhythms that support Agile execution from day one. | - Determine the key activities that occur after contract award, including kickoff planning, team ramp-up, and establishing a shared delivery baseline. |

### Topics
- Contract kickoff  
- Introduction to readings: Cloud and XaaS procurement best practice  
- **Activity:** Cloud Breach Facilitation Exercise Facilitation Guide  


## Sprint 4: Contract Management and Problem Resolution

| Learning Elements | Descriptions | Learning Objectives |
| ----------------- | ------------ | ------------------- |
| **Contract Management and Problem Resolution** | This sprint focuses on managing digital service contracts after award, with an emphasis on identifying and addressing performance issues. Learners will explore techniques for monitoring vendor progress, resolving delivery challenges, and applying remedies within the bounds of the contract. The sprint also highlights the importance of proactive communication and documentation throughout the performance period. | - Determine appropriate strategies for course correction or exit when digital service delivery is off track.<br>- Demonstrate how to negotiate consideration or remediation actions within the context of Agile delivery. |

### Topics
- Federal IT acquisition, management, and software engineering practices  
- **Activity:** Federal IT acquisition, management, and software engineering practices  
- Exit strategy  
- Exit strategy: Key questions for analysis  

---

## Module 5: Grow

Grow: Apply techniques to create the culture of innovation within your sphere that enables you and others to effectively lead and influence customers to the best solutions.

## Sprint 1: Leading Change As An Individual

| Learning Elements | Descriptions | Learning Objectives |
| ----------------- | ------------ | ------------------- |
| **Leading Change As An Individual** | Defines change agents; describes effective influence strategies; and approaches to building networks and coalitions to facilitate change. | - Identify your spheres of influence within the acquisition environment.<br>- Recognize common challenges that arise when engaging stakeholders across those spheres.<br>- Plan influence strategies and conversations tailored to the challenges and opportunities in your agency or live digital assignment. |

### Topics
- Preparing for and having an influence conversation  
- Difficult conversations  
- Knowledge check  
- Building your resilience
- Cultivating your growth mindset
- Wellness rituals to support you in times of transition
- Analyze where the “no” came from
- Should I fight this battle, or how might I adjust my approach to make it more “winnable”?
- "What to do when you’re told no" framework in action
- Adjust approach & identify lessons learned
- Telling your procurement story



## Sprint 2: Leading Organizational Change - Continuous Improvement and Scalable Practices

| Learning Elements | Descriptions | Learning Objectives |
| ----------------- | ------------ | ------------------- |
| **Leading Organizational Change - Continuous Improvement and Scalable Practices** | This sprint focuses on strategies for staying current with emerging technologies and continuously improving acquisition practices, as well as approaches to scaling successful methods across organizations, supported by examples from the broader federal agency community. | - Assess your strengths and change style to develop a personal plan for contributing to and promoting change within your agency and the broader government community. |

### Topics
- Staying current and driving change: your role in continuous improvement
- Staying current with emerging tech and trends
- Continuous improvement in everyday procurement
- The case for creating practical guides: from playbooks to toolkits and beyond
- Exploring your role as an ambassador of change
- Kotter model introduction
- Self-assessment: what’s your change style?
- Create your change contribution plan
- Wrap-up & call to action

---

## Module 6: Apply skills

Apply: Apply techniques learned in the course through various activities.

# Module 6: Apply

| **Learning Objectives** | 
| --- | 
| Demonstrate the ability to conduct discussions and interviews with stakeholders across your sphere of influence. <br><br> Apply shadowing, detailed observations, or rotational assignments with digital service experts to better understand and integrate into the culture. <br><br> Utilize a “small team of teams” approach to design, execute, and reflect on a live digital assignment. |

| **Learning Elements** | **Descriptions** |
| --- | --- |
| **Stakeholder Interview Assignment** | A structured opportunity for participants to engage agency leaders who influence digital services, procurement, or policy. By conducting 2–4 interviews, participants practice influence, build empathy, and deepen their understanding of organizational dynamics. Full guidance and criteria for this assignment can be found in the Appendix. |
| **Shadowing Assignment** | An observational learning experience where participants spend at least four hours with a digital service delivery team. By witnessing Agile workflows, user-centered design, and cross-functional collaboration, participants gain firsthand insight into modern delivery practices. Full guidance and criteria for this assignment can be found in the Appendix. |
| **Live Digital Assignment** | The program’s capstone project, simulating the full lifecycle of a digital service acquisition. Working in teams, participants identify a real procurement challenge, apply Agile and human-centered design principles, and produce proposals, reviews, and presentations. Full guidance and criteria for this assignment can be found in the Appendix. |

---

## Threaded Case Scenario Guidance


### Purpose of case scenario integration

This guide provides a high-level overview of how vendors delivering the DITAP program should approach the integration of a case scenario across the course modules. It outlines the purpose of the case scenario, expectations for integration across the curriculum, and guidance for selecting alternative case studies if needed.

### Case scenario overview

The recommended case scenario for the DITAP program is _Navigating Stakeholder and Decision-Making Challenges,_ written by Cynuria. This case provides a multi-phase scenario aligned with key DITAP competencies and supports learners in connecting theory to practice in a realistic digital acquisition context.

The Cynuria case scenario includes multiple milestones and decision points designed to evolve alongside the course curriculum. It is structured to:

- Introduce a realistic digital acquisition challenge (CRM procurement)
- Showcase policy, technical, and stakeholder complexity
- Enable applied learning through scenario-based activities
- Foreshadow and revisit decision-making moments in alignment with course content

Two versions of the Cynuria case scenario are available:

- **Comprehensive version**: This version includes both facilitator and student guidance. It is structured with clear milestones and aligned touchpoints for integration across modules. It’s the most thorough and detailed resource.
- **Narrative version**: This version presents the same core scenario in a shorter, story-driven format. It’s designed for readability and engagement, and may include narrative cliffhangers to spark discussion. Vendors may choose to use this version as a supplemental or primary reading depending on audience and delivery style.

Vendors are encouraged to use the Cynuria case scenario unless they have a compelling reason to substitute another. If a different case scenario is used, it must:

- Include multiple touchpoints across at least four modules
- Feature a narrative that evolves and builds in complexity
- Include opportunities for stakeholder analysis, solution evaluation, delivery planning, and leadership or change management
- Allow learners to apply frameworks and decision-making tools across modules
- Reflect realistic constraints and trade-offs in government digital acquisition

#### Pacing guide

The threaded case scenario unfolds alongside the course modules, with each activity reinforcing key concepts and building toward an integrated understanding of digital service procurement. Some activities are core milestones drawn directly from the Cynuria case materials; others are extension activities designed to deepen learning or connect to real-world application. The pacing chart below outlines when each case activity appears, which sprint it aligns to, and how it connects to major course milestones.

| **Module** | **Sprint** | **Activity Title** | **Case Scenario Milestone Alignment** |
|------------|------------|---------------------|----------------------------------------|
| **Module 1** | Sprint 1 | Introduction to Cynuria Case | Not a formal milestone, serves as Case scenario narrative intro |
| **Module 2** | Sprint 1 | Stakeholder Mapping | Milestone 1 |
| **Module 2** | Sprint 4 | Market Research Planning | Not a formal milestone, builds on Milestone 1 |
| **Module 2** | Sprint 4 | FAR 10 Integration Assignment | Not a formal milestone. It’s an extension activity. |
| **Module 3** | Sprint 1 | Solution Evaluation with SWOT Analysis | Milestone 2 |
| **Module 3** | Sprint 2 | Evaluating Data Security Solutions with SWOT & Cost Estimation | Milestone 3 |
| **Module 3** | Sprint 3 | Designing a Solicitation Strategy | Not a formal milestone, builds on Milestones 2 and 3 |
| **Module 4** | Sprint 3 | Laying the Groundwork for Agile Delivery | Applies prior decisions from Milestones 2 and 3 |
| **Module 4 or 5** |  | Laying Out a Recommendation | Milestones 4 & 5 |
| **Module 5** | Sprint 3 | Leading Change and Navigating Resistance | Integrates entire case context |



#### Integration guidance

Vendors are responsible for ensuring the case scenario is threaded throughout the curriculum in a way that:

- Aligns with the learning objectives of each module
- Reinforces key digital service delivery principles and practices
- Provides a common anchor for group discussion, assignments, and applied activities

Integration may vary slightly depending on program design, but generally includes:

- Early exposure to the full case scenario (Module 1)
- Deep dives into individual milestones aligned with module competencies (Modules 2–3)
- Continued reference during planning and implementation content (Modules 4–5).
- Synthesis and final presentation using the case (Module 6)

Vendors should ensure that:

- Participants receive the full case scenario early in the program
- Assigned readings are clearly communicated in advance of each module
- Participants are given multiple opportunities to apply tools and concepts to the case throughout the course

## Facilitating the threaded case study

### General facilitator guidance

#### Purpose of the case scenario

The threaded case scenario is a tool for deepening understanding and sparking application across the course. Through a fictional—but realistic—procurement scenario, participants explore the complexity of digital service delivery in government and connect course concepts to their own day-to-day challenges. The case scenario helps participants:

- Apply concepts in a realistic, evolving context
- Practice critical thinking, stakeholder engagement, and strategic decision-making
- Surface parallels to their own work and identify opportunities for influence and improvement

Each case scenario activity reinforces the sprint’s learning objectives and serves as a springboard for meaningful, context-specific conversation.

_Detailed guidance for each activity—including suggested framing, timing, and prompts—is available in the corresponding facilitator guide._

### Flexible format

Most case activities are run in small groups with a brief whole-group share-out. Refer to the pacing guide for timing recommendations and feel free to adjust based on group size, energy, and time available. There’s plenty more room for creativity in how you run these sessions. Think of what’s provided as a springboard.

### Key facilitation moves

**Anchor in course content**  
Use the case scenario to reinforce frameworks and key ideas introduced in each sprint—drawing from both live session slides and self-paced materials.

**Create call-back moments**  
Encourage learners to connect current decisions to earlier moments in the case or in their own work. What patterns or assumptions are still at play? How have past decisions shaped the present?

**Promote evidence-based reasoning**  
Ask learners to ground their analysis in specific details from the case—emails, timelines, decisions, and organizational behavior.

**Bridge to lived experience**
If groups get stuck, invite reflection on their own environments. What makes collaboration hard across functions? What constraints or opportunities do they see in their work?

**Challenge assumptions** 
Prompt participants to identify and question assumptions Casey’s team may be making. What’s being overlooked? What alternate paths are possible?

**Broaden perspectives** 
Encourage groups to consider nontraditional sources of insight, such as frontline staff, legacy system documentation, or indirect stakeholders.

**Connect discovery to design** 
Especially in Modules 2–3, guide learners to see how early discovery findings shape later acquisition and implementation decisions.

**Elevate learner expertise**  
Your role is to create space for rich discussion—not to lecture. Emphasize the expertise in the room.

**Right-size the vendor role**  
Encourage analysis of how participants themselves can lead and influence—rather than focusing only on vendor behavior or external constraints.  

---

## LMS Guidance

As part of the course introduction, vendors should provide learners with a brief orientation to the Learning Management System (LMS). This orientation should be tailored to the specific LMS being used and designed to help learners feel comfortable navigating the system from the start. The goal is to set learners up for success, reduce confusion, and ensure they can focus on the course content.

### Key elements to cover in your LMS orientation include:

**Accessing the LMS:** Provide clear instructions for logging in, setting up accounts, and accessing the course. Include relevant links and any credentials learners may need.

**Course layout and structure:** Give an overview of how the course is organized, including the modules, lessons, and any assessments. Highlight where learners should begin and the recommended progression through the content.

**Finding key course elements:** Show learners where to locate modules, assignments, assessments, required materials, and other resources. Clear navigation instructions will help learners find what they need quickly.

**Tracking progress:** Explain any progress indicators available in the LMS, such as completed modules or scores, and how learners can use these tools to monitor their own learning.

**Communication tools:** Outline how learners can interact with instructors/facilitators, support staff, and peers. This might include discussion boards, messaging features, announcements, or office hours.

**Technical support:** Provide information on how learners can get help if they encounter technical issues, including contact points and response expectations.

### Integrating materials into your LMS

Vendors should ensure that all course materials, modules, assessments, and other materials are properly integrated into their LMS. This includes uploading files, linking to external resources, and configuring assessments so that learner progress and completion are tracked accurately. Clear labeling, consistent module sequencing, and accessible navigation are critical to providing a seamless learner experience. Whenever possible, test the course in the LMS environment before launch to confirm that all interactive content, links, and tracking functions work as intended.

Vendors should design and integrate course materials in accordance with accessibility standards, ensuring all learners, including those with disabilities, can engage with the content. This includes providing alternative text for images, captions or transcripts for videos, keyboard navigation for interactive elements, and clear, consistent formatting for readability. Vendors should also ensure that color choices, font sizes, and contrast meet accessibility guidelines, and that all links and instructions are clear and descriptive. Incorporating these practices from the start helps provide an inclusive learning experience and supports compliance with accessibility requirements.

### LiaScript integration

This course was built using LiaScript, an open-source framework for interactive online learning. LiaScript allows for dynamic content, such as embedded quizzes, multimedia, and branching scenarios. Learners can complete exercises directly within the course environment, receive immediate feedback, and track their progress in real time. For course providers, LiaScript supports flexible formatting and consistent presentation across modules, making it easier to maintain quality and accessibility standards.




